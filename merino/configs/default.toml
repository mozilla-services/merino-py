# Default configurations that may be overridden by the counterparts defined in
# `development.toml` or `production.toml` or environment variables.

# Configurations can be defined by:
#
# * Directly under the `[default]` table, e.g.
#
#   [default]
#   foo = "bar"
#
# * Or use an inline table if it has multiple sub-configurations, e.g.
#
#   [default]
#   foo = { bar = "baz", egg = "spam" }
#
# * Or use a nested table if it's hard to define by above, e.g.
#
#   [default.foo]
#   bar = "baz"
#   egg = "spam"
#   fiz = "buz"

[default]
debug = false

[default.runtime]
# A float timeout (in seconds) for all queries issued in "web/api_v1.py".
# Each provider can override this timeout by specifying a provider-level
# timeout with the same name `query_timeout_sec`. See `accuweather` as an
# example.
query_timeout_sec = 0.2

[default.logging]
# Any of "DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"
level = "INFO"
# Any of "mozlog" (i.e. JSON) or "pretty"
format = "mozlog"
can_propagate = false

[default.web.api.v1]
# Setting to contol the limit of optional client variants passed
# to suggest endpoint as part of experiments or rollouts.
client_variant_max = 10
# Values passed into Query object for FastAPI query parameter validator.
# Sets limitation on the maximum string length of a query.
client_variant_character_max = 100
query_character_max = 500

[default.metrics]
dev_logger = false
host = "localhost"
port = 8092

[default.deployment]
# The deployment workflow is expected to set this to true for canary pods
canary = false

[default.location]
# Path to the MaxMindDB file. This should be overridden in production.
maxmind_database = "./dev/GeoLite2-City-Test.mmdb"
# This can be set to facilitate manual testing during development.
client_ip_override = ""

[default.remote_settings]
server = "https://firefox.settings.services.mozilla.com"
bucket = "main"
collection = "quicksuggest"
# Authorization token when uploading suggestions
auth = ""
# The maximum number of suggestions to store in each attachment when uploading
# suggestions
chunk_size = 200
# Delete existing records before uploading new records
delete_existing_records = true
# Log changes but don't actually make them when uploading suggestions
dry_run = false
# Default score to set in suggestions uploaded to remote settings
score = 0.25

[default.sentry]
# Any of "release", "debug", or "disabled".
# Using "debug" will enable logging for Sentry.
mode = "disabled"
# Sentry will not send events out when given an empty string `dsn`.
dsn = ""
# Any of "prod", "stage", or "dev".
env = "dev"
# A setting for the tracing sample rate. Should be a float in range [0, 1.0].
traces_sample_rate = 0

[default.providers.accuweather]
type = "accuweather"
backend = "accuweather"
cache = "none"
enabled_by_default = false
score = 0.3
query_timeout_sec = 5.0

[default.providers.accuweather.cache_ttls]
# Cache TTLs for weather data
location_key_ttl_sec = 604800 # 7 days
current_condition_ttl_sec = 1800 # 1/2 hr
forecast_ttl_sec = 3600 # 1 hr

[default.accuweather]
# Our API key used to access the AccuWeather API.
api_key = ""
# The remainder of these variables are related to endpoint URLs.
url_base = "https://apidev.accuweather.com"
# The name of the query param whose value is the API key, not the key itself.
url_param_api_key = "apikey"
url_current_conditions_path = "/currentconditions/v1/{location_key}.json"
url_forecasts_path = "/forecasts/v1/daily/1day/{location_key}.json"
# The placeholder for the location key used by the above two configurations.
url_location_key_placeholder = "{location_key}"
url_postalcodes_path = "/locations/v1/postalcodes/{country_code}/search.json"
url_postalcodes_param_query = "q"
# The name of the partner code query param appended to the current conditions and forecast links in
# AccuWeather responses, as described in https://apidev.accuweather.com/developers/partner-code.
# Note that this is the name of the partner code parameter, not the partner code itself.
url_param_partner_code = "partner"

[default.providers.adm]
type = "adm"
# Whether or not this provider is enabled by default.
enabled_by_default = true
# The backend of the provider. Either "remote-settings" or "test".
backend = "remote-settings"
# The cron job should tick more frequently than `resync_interval_sec` so that
# the resync failure can be retried soon.
cron_interval_sec = 60
resync_interval_sec = 10800
score = 0.3

[default.amo.dynamic]
# This is the URL for the Addons API to get more information for particular addons
api_url = "https://addons.mozilla.org/api/v5/addons/addon/"

[default.providers.amo]
type = "amo"
enabled_by_default = false
score = 0.25
# Specifies which backend to use. Should default to dynamic backend.
# Currently turned off so that we don't make repeated calls to Addon API if it doesn't work.
backend = "dynamic"
# The minimum number of characters to be considered for matching.
min_chars = 4
# The re-syncing frequency for the AMO data. Defaults to daily.
resync_interval_sec = 86400
# The frequency that the cron checks to see if re-syncing is required.
# This should be more frequent than the `resync_interval_sec` to retry
# on errors. Defaults to every minute.
cron_interval_sec = 60


[default.providers.top_picks]
type = "top_picks"
enabled_by_default = true
score = 0.25
query_char_limit = 4
firefox_char_limit = 2
top_picks_file_path = "dev/top_picks.json"

[default.providers.wikipedia]
type = "wikipedia"
enabled_by_default = true
# The backend of the provider. Either "elasticsearch" or "test".
backend = "elasticsearch"
# The URL of the cluster that we want to connect to.
es_url = "http://localhost:9200"
# The base64 key used to authenticate on the Elasticsearch cluster
es_api_key = ""
# Elasticsearch index
es_index = "enwiki-v1"
# The maximum suggestions for each search request.
es_max_suggestions = 3
# The timeout (in millisecond) for each request to ES
es_request_timeout_ms = 5000
query_timeout_sec = 5.0
# Suggestion score
score = 0.23


[default.jobs.wikipedia_indexer]
# The URL of the Elasticsearch cluster for indexing job.
# This takes precedent over the Cloud ID (i.e. if you pass both,
# we will choose the URL over the Cloud ID).
es_url = ""
# Elasticsearch API key for indexing job
es_api_key = ""
# Elasticsearch API key for indexing job
es_alias = "enwiki-{version}"
# Index version that will be written.
index_version = "v1"
# Estimate of the total documents in the elasticsearch index.
total_docs = 6_400_000
# GCS path. Combined bucket and object prefix (folders).
gcs_path = ""
# GCP project name where the GCS bucket lives.
gcp_project = ""
# Wikipedia export base URL
export_base_url = "https://dumps.wikimedia.org/other/cirrussearch/current/"
# Blocklist file as CSV. Contains a list of the categories for articles that we want to block.
blocklist_file_url = "https://raw.githubusercontent.com/mozilla/search-terms-sanitization/7ab819c7515c526e6a407b08ba8e78d3bdb7f4e9/non_sensitive/wikipedia-content-moderation/blocklist_cats.csv"

[default.jobs.navigational_suggestions]
# GCP project name that contains domain data tables
source_gcp_project = ""
# GCP project name where the GCS bucket lives
destination_gcp_project = ""
# GCS bucket name where domain metadata will be uploaded
destination_gcs_bucket = ""
# CDN hostname of the GCS bucket where domain metadata will be uploaded
destination_cdn_hostname = ""
# Flag to enable uploading the domain metadata to GCS bucket even if it aleady exists there
force_upload = false
# Minimum width of the domain favicon required for it to be a part of domain metadata
min_favicon_width = 48

[default.jobs.amo_rs_uploader]
# The "type" of each remote settings record
record_type = "amo-suggestions"
