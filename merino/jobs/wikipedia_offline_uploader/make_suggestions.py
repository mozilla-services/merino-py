#!/usr/bin/env python3
"""Generate Firefox Suggest suggestions based on the Wikipedia top viewed pages.

It expects inputs from stdin in the JSON format, which can be generated by
`top_n_by_frequency.py` or `top_n_by_recency.py`. The results, which are ready
for Remote Settings, are dumped to the "rs-data" directory located at the top
level of the project.


Usage:

    # Generate 7000 Wikipedia suggestions based on frequency for last 90 days
    # Note that over-production is done for producer `./top_n_by_frequency`,
    # see reasoning down low
    $ ./fetch-wikipedia-top-pages.sh 90 | ./top_n_by_frequency.py 8000 | ./make_suggestions.py 7000

    # Generate 7000 Wikipedia suggestions based on recency for last 30 days
    $ ./fetch-wikipedia-top-pages.sh 30 | ./top_n_by_recency.py 8000 | ./make_suggestions.py 7000

    # Generate 10000 Wikipedia suggestions based on recency for last 30 days
    $ ./fetch-wikipedia-top-pages.sh 30 | ./top_n_by_recency.py 11000 | ./make_suggestions.py 10000

Note:
    * If not specified, the default size of the output suggestion is 7000
    * The keywords are generated based on the title field of the input. All `_`s
      are replaced with whitespaces and then lowercased before processing.
      Other punctuations (`,`, `.`, `:` etc.) are left untouched
    * The minimal keyword size is controlled by `MIN_KEYWORD_LEN`, which is set
      to `2` to match the minimal suggestion trigger threshold in Firefox
    * Various leading words are skipped in keywords generating:
        * `the`, `an`, and `a`
        * leading numerics such as `2022`
    * Each keyword is only associated with one suggestion. Keywords are assigned
      to suggestions in an FIFO manner based on the order (frequency or recency)
      of the associated Wikipedia page
    * Each suggestion should have at least `MIN_KEYWORDS` keywords, otherwise
      that suggestion will be excluded in the output. To produce the expected
      amount suggestions, it's a good idea to provide a little more (+10%) than
      expected in the upstream producers (i.e. top_n_by_frequency or top_n_by_recency)
    * To avoid having excessive keyword list for long titles, the total number of
      keywords for each suggestion is capped by `MAX_KEYWORDS`
    * Suggestion `id` is hardcoded to `0` for now. We might assign a valid ID to
      each suggestion later if needed
    * Suggestion `icon` is also hardcoded to `ICON_ID`, which is already uploaded
      to Remote Settings
    * The path of the suggestion URL is escaped (quoted) so that it's safe to
      use and store
"""

import json
import re
import sys
from itertools import filterfalse, islice, takewhile
from typing import List, Pattern, Set, Generator, Any
from urllib.parse import quote

# Max # of keywords for each suggestion.
MAX_KEYWORDS = 25

# Min # of keywords for each suggestion. We should *not* provide a suggestion
# if its available keywords are fewer than this threshold.
MIN_KEYWORDS = 3

# Minimal keyword length
MIN_KEYWORD_LEN = 2

# URL prefix for Wikipedia
URL_PREFIX = "https://{language}.wikipedia.org/wiki/"

# Prefix of the output file
OUTPUT_PREFIX = "./rs-data/data-wikipedia"

# The hardcoded icon ID on Remote Settings
ICON_ID = "161351842074695"

# Max # of suggestions for a Remote Settings attachment
RS_CHUNK_SIZE = 200

# A set to store all the keywords observed thus far.
SEEN_KEYWORDS: Set[str] = set([])

# The leading words to be skipped
SKIP_WORDS: Pattern = re.compile(r"(\d+|the|an|a)$")

# The directory for adM provided suggestions. This is used to load all the
# keywords of the in-flight sponsored suggestions.
AMP_SOURCE_DIR = "../source-data/"

# A set to store all the inflight sponsored keywords
SPONSORED_KEYWORDS: Set[str] = set()


def make_keywords(words: List[str]):
    """Generate partial keywords."""
    prefix = " ".join(takewhile(SKIP_WORDS.match, words))
    unwords = " ".join(words)
    # If prefix is not empty, shift one (+1) for the followed whitespace
    begin = len(prefix) + 1 + MIN_KEYWORD_LEN if prefix else MIN_KEYWORD_LEN
    partials = [unwords[:i] for i in range(begin, len(unwords) + 1)]
    return list(
        islice(
            filterfalse(lambda x: x in SEEN_KEYWORDS or x in SPONSORED_KEYWORDS, partials),
            MAX_KEYWORDS,
        )
    )


def scan(language) -> Generator[dict[str, str | list[str] | list[list[int]] | int], Any, None]:
    """Generate Suggestion."""
    for article in json.loads(sys.stdin.read()):
        title = article["title"]
        keywords = make_keywords(title.lower().split("_"))
        title_string = title.replace("_", " ")
        wiki_title_string = "WikipÃ©dia" if language == "fr" else "Wikipedia"

        if len(keywords) >= MIN_KEYWORDS:
            for keyword in keywords:
                SEEN_KEYWORDS.add(keyword)
            yield {
                "id": 0,  # FIXME: assign a suggestion ID.
                "url": f"{URL_PREFIX.format(language=language)}{quote(title)}",
                "iab_category": "5 - Education",
                "icon": ICON_ID,
                "advertiser": "Wikipedia",
                "title": f"{wiki_title_string} - {title_string}",
                "keywords": keywords,
                "full_keywords": [[title_string, len(keywords)]],
            }


def main() -> None:
    """Construct Suggestions and write to json files."""
    language = "en"
    if len(sys.argv) < 2:
        want = 7000
    else:
        want = int(sys.argv[1])

    if len(sys.argv) == 3:
        language = sys.argv[2]

    n_suggestions = 0
    n_chunked = 0
    gen = scan(language)

    while True:
        suggestions = list(islice(gen, min(want - n_chunked * RS_CHUNK_SIZE, RS_CHUNK_SIZE)))

        if not suggestions:
            break

        with open(
            f"{OUTPUT_PREFIX}-{language}-{n_chunked*RS_CHUNK_SIZE:04}"
            f"-{(n_chunked+1)*RS_CHUNK_SIZE:04}.json",
            "w",
        ) as f:
            json.dump(suggestions, f, ensure_ascii=False)

        n_chunked += 1
        n_suggestions += len(suggestions)

        if n_chunked * RS_CHUNK_SIZE >= want:
            break

    print(f"Total suggestions: {n_suggestions}\n" f"Total keywords: {len(SEEN_KEYWORDS)}")


if __name__ == "__main__":
    main()
