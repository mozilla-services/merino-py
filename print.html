<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Merino Book</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item affix "><a href="intro.html">Intro</a></li><li class="chapter-item affix "><li class="part-title">General Documentation</li><li class="chapter-item "><a href="api.html"><strong aria-hidden="true">1.</strong> Using the HTTP API</a></li><li class="chapter-item "><a href="firefox.html"><strong aria-hidden="true">2.</strong> Configuring Firefox and Merino Environments</a></li><li class="chapter-item "><a href="data.html"><strong aria-hidden="true">3.</strong> Data collection</a></li><li class="chapter-item "><a href="social-contract.html"><strong aria-hidden="true">4.</strong> Social contract</a></li><li class="chapter-item "><a href="dev/index.html"><strong aria-hidden="true">5.</strong> Working on the Code</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="dev/content-moderation.html"><strong aria-hidden="true">5.1.</strong> Content Moderation</a></li><li class="chapter-item "><a href="dev/dependencies.html"><strong aria-hidden="true">5.2.</strong> Dependencies</a></li><li class="chapter-item "><a href="dev/logging-and-metrics.html"><strong aria-hidden="true">5.3.</strong> Logging and Metrics</a></li><li class="chapter-item "><a href="dev/middlewares.html"><strong aria-hidden="true">5.4.</strong> Middlewares</a></li><li class="chapter-item "><a href="dev/feature_flags.html"><strong aria-hidden="true">5.5.</strong> Feature Flags</a></li><li class="chapter-item "><a href="dev/release-process.html"><strong aria-hidden="true">5.6.</strong> Release Process</a></li><li class="chapter-item "><a href="dev/profiling.html"><strong aria-hidden="true">5.7.</strong> Profiling</a></li><li class="chapter-item "><a href="testing/index.html"><strong aria-hidden="true">5.8.</strong> Testing & Test Strategy</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="testing/unit-tests.html"><strong aria-hidden="true">5.8.1.</strong> Unit Tests</a></li><li class="chapter-item "><a href="testing/integration-tests.html"><strong aria-hidden="true">5.8.2.</strong> Integration Tests</a></li><li class="chapter-item "><a href="testing/load-tests.html"><strong aria-hidden="true">5.8.3.</strong> Load Tests</a></li></ol></li></ol></li><li class="chapter-item "><a href="operations/index.html"><strong aria-hidden="true">6.</strong> Operations</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="operations/rollback.html"><strong aria-hidden="true">6.1.</strong> Rollback</a></li><li class="chapter-item "><a href="operations/blocklist-nav-suggestions.html"><strong aria-hidden="true">6.2.</strong> Modify Navigational Suggestions Blocklist</a></li><li class="chapter-item "><a href="operations/blocklist-wikipedia.html"><strong aria-hidden="true">6.3.</strong> Modify Wikipedia Suggestions Blocklist</a></li><li class="chapter-item "><a href="operations/testfailures.html"><strong aria-hidden="true">6.4.</strong> Test Failures in CI</a></li><li class="chapter-item "><a href="operations/configs.html"><strong aria-hidden="true">6.5.</strong> Configs</a></li><li class="chapter-item "><a href="operations/elasticsearch.html"><strong aria-hidden="true">6.6.</strong> Elasticsearch</a></li><li class="chapter-item "><a href="operations/jobs.html"><strong aria-hidden="true">6.7.</strong> Jobs</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="operations/jobs/navigational_suggestions.html"><strong aria-hidden="true">6.7.1.</strong> Navigational Suggestions</a></li><li class="chapter-item "><a href="operations/jobs/dynamic-wiki-indexer.html"><strong aria-hidden="true">6.7.2.</strong> Dynamic Wikipedia Indexer</a></li><li class="chapter-item "><a href="operations/jobs/csv-remote-settings.html"><strong aria-hidden="true">6.7.3.</strong> Remote Settings CSV Uploader</a></li></ol></li></ol></li><li class="chapter-item "><li class="part-title">ADR</li><li class="chapter-item "><a href="adr/index.html"><strong aria-hidden="true">7.</strong> Archive</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="adr/0001-locust-vs-k6-merino-py-performance-test-framework.html"><strong aria-hidden="true">7.1.</strong> Load Test Framework: Locust VS K6</a></li><li class="chapter-item "><a href="adr/0002-merino-general-response.html"><strong aria-hidden="true">7.2.</strong> General API Response</a></li><li class="chapter-item "><a href="adr/0003-test-containers.html"><strong aria-hidden="true">7.3.</strong> Adopt Testcontainers for Integration Testing</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Merino Book</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="merino"><a class="header" href="#merino">Merino</a></h1>
<p>Merino is a service that provides address bar suggestions and curated recommendations
to Firefox. Some of this content comes from third party providers. In this case, Merino
serves as a privacy preserving buffer. User input in the address bar is handled by Merino
and any clicked impression will be delegated to a Mozilla-controlled service which will
then send an interaction ping if defined in the request and not to a provider directly.
See <a href="https://merino.services.mozilla.com/docs">API documentation</a> for more details.</p>
<h2 id="table-of-contents"><a class="header" href="#table-of-contents">Table of Contents</a></h2>
<p><a href="./api.html">api.md - API Documentation</a> describes endpoints, query parameters, request and response headers, response objects and details on the suggestion objects.</p>
<p><a href="./firefox.html">firefox.md - Firefox and Merino Environments</a> describes how to enable
Merino in Firefox and lists the endpoints for the service in Production,
State and Dev.</p>
<p><a href="./data.html">data.md - Data, Metrics, Logging</a> describes all metrics and logs.</p>
<p><a href="./dev/index.html">dev/index.md - Basic Developer Docs</a> describes basics of working on Merino.</p>
<p><a href="./dev/dependencies.html">dev/dependencies.md - Development Dependencies</a> describes the development
dependencies required for Merino.</p>
<p><a href="./dev/logging-and-metrics.html">dev/logging-and-metrics.md - Logging and Metrics</a> describes metrics, logging, and telemetry.</p>
<p><a href="./dev/release-process.html">dev/release-process.md - Release Process</a> describes the release process of Merino in detail.</p>
<p><a href="./dev/testing.html">dev/testing.md - Testing</a> describes unit, integration and load tests for Merino.</p>
<p><a href="./dev/profiling.html">dev/profiling.md - Profiling</a> describes how to profile Merino to address performance issues.</p>
<p><a href="./operations/configs.html">operations/configs.md - Configuring Merino</a> describes configuration management
of the project, Dynaconf setup, and the configuration of the HTTP server, logging, metrics, Remote Settings, and Sentry.</p>
<p><a href="./operations/elasticsearch.html">operations/elasticsearch.md - Elasticsearch Operations</a> describes some functionality and operations that
we do on the Elasticsearch cluster.</p>
<p><a href="./operations/jobs.html">operations/jobs.md - Merino Jobs</a> describes the jobs that are configured in Merino. Indicate where the jobs
exist and link to the details for how the jobs are run.</p>
<h2 id="about-the-name"><a class="header" href="#about-the-name">About the Name</a></h2>
<p>This project drives an important part of Firefox's &quot;felt experience&quot;. That is,
the feeling of using Firefox, hopefully in a delightful way. The word &quot;felt&quot; in
this phrase refers to feeling, but it can be punned to refer to the
<a href="https://en.wikipedia.org/wiki/Felt">textile</a>. Felt is often made of wool, and
Merino wool (from Merino sheep) produces exceptionally smooth felt.</p>
<h2 id="architecture"><a class="header" href="#architecture">Architecture</a></h2>
<pre class="mermaid">flowchart TD
    User[\fa:fa-user User/]

    subgraph Firefox [fa:fa-firefox Firefox]
        online(Online Search and Suggest)
        offline(Offline Search and Suggest&lt;br/&gt;fetches adMarketplace, static Wikipedia, &lt;br/&gt;and other suggestions.&lt;br/&gt; Offline mode is fallback if Merino times out.)
    end

    User --&gt; |Accessing the Firefox URL bar| Firefox

    subgraph Merino [fa:fa-leaf Merino]
        srh(fa:fa-gears Suggest Request Handler)

        subgraph middleware [fa:fa-paperclip Middleware]
            Geolocation
            Logging
            UserAgent
            Metrics
        end

        maxmind[(MaxmindDB)]
        Geolocation --&gt; maxmind

        srh -..- middleware

        subgraph providers [fa:fa-truck Providers]
            adm(adm)
            amo(amo)
            geolocation(geolocation)
            toppicks(top-picks)
            weather(weather)
            wikipedia(wikipedia)
        end

        srh --&gt; adm
        srh --&gt; amo
        srh --&gt; geolocation
        srh --&gt; toppicks
        srh --&gt; weather
        srh --&gt; wikipedia

        subgraph backends [fa:fa-server Backends]
            rsb(remote settings)
            accuweather(accuweather)
            elastic(elastic)
            toppicks_back(top picks)
            dynamic_amo(dynamic addons)

        end

        adm --&gt; rsb
        amo --&gt; dynamic_amo
        toppicks --&gt; toppicks_back
        weather --&gt; accuweather
        wikipedia --&gt; elastic
    end


    subgraph &quot;Airflow (Merino Jobs)&quot;
        wikipedia_sync(Wikipedia Sync)
        toppicks_sync(Top Picks Sync)
        addons_sync(Addons Remote Settings Upload)
    end

    addons_api(Addons API)
    dynamic_amo --&gt; addons_api

    elastico[(Elasticsearch)]
    elastic --&gt; elastico
    wikipedia_sync ..- |Syncs Wikipedia entries weekly| elastico

    accuweather_api(Accuweather API)
    accuweather ..-&gt; accuweather_api

    redis[(Redis Cache)]
    accuweather ..-&gt; |tries to query cache first| redis

    kinto[(Remote Settings)]
    rsb --- kinto
    addons_sync ..- |Add Addons Suggestions to Remote Settings| kinto

    toppicks_data[(GCS Top Picks Data,&lt;br/&gt;a list of Mozilla curated popular sites and metadata to be &lt;br/&gt;displayed on browser)]
    toppicks_sync ..-&gt; toppicks_data

    online --&gt; |/api/v1/suggest| srh
    offline ..- kinto
</pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="merino-api-documentation"><a class="header" href="#merino-api-documentation">Merino API documentation</a></h1>
<p>This page describes the API endpoints available on Merino.</p>
<p>The autogenerated API documentation exists <a href="https://merinopy.services.mozilla.com">here</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configuring-firefox-and-merino-environments"><a class="header" href="#configuring-firefox-and-merino-environments">Configuring Firefox and Merino Environments</a></h1>
<p>Merino has been enabled by default in Firefox. Though, you will need to enable
the data sharing for Firefox Suggest to fully enable the feature. To enable it,
type <code>about:config</code> in the URL bar set the Firefox preference
<code>browser.urlbar.quicksuggest.dataCollection.enabled</code> to <code>true</code>. By default,
Merino will connect to the production environments. This is controlled with the
<code>browser.urlbar.merino.endpointURL</code> preference. See below for other options.</p>
<p>You can also query any of the endpoint URLs below with something like:</p>
<pre><code class="language-sh">curl 'https://stage.merino.nonprod.cloudops.mozgcp.net/api/v1/suggest?q=your+query'
</code></pre>
<h2 id="environments"><a class="header" href="#environments">Environments</a></h2>
<h3 id="production"><a class="header" href="#production">Production</a></h3>
<p><em>Endpoint URL</em>: <a href="https://merino.services.mozilla.com/api/v1/suggest">https://merino.services.mozilla.com/api/v1/suggest</a></p>
<p>The primary environment for end users. Firefox is configured to use this by
default.</p>
<h3 id="stage"><a class="header" href="#stage">Stage</a></h3>
<p><em>Endpoint URL</em>: <a href="https://stage.merino.nonprod.cloudops.mozgcp.net/api/v1/suggest">https://stage.merino.nonprod.cloudops.mozgcp.net/api/v1/suggest</a></p>
<p>This environment is used for manual and load testing of the server. It is not
guaranteed to be stable or available. It is used as a part of the deploy process
to verify new releases before they got to production.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="data-collection"><a class="header" href="#data-collection">Data collection</a></h1>
<p>This page should list all metrics and logs that Merino is expected to emit in
production, including what should be done about them, if anything.</p>
<h2 id="logs"><a class="header" href="#logs">Logs</a></h2>
<p>This list does not include any <code>DEBUG</code> level events, since those are not logged
by default in production. The level and type of the log is listed.</p>
<p>Any log containing sensitive data must include a boolean field <code>sensitive</code>
that is set to <code>true</code> to exempt it from flowing to the generally accessible
log inspection interfaces.</p>
<h3 id="merino-apis"><a class="header" href="#merino-apis">Merino APIs</a></h3>
<ul>
<li>
<p><code>INFO web.suggest.request</code> - A suggestion request is being processed. This
event will include fields for all relevant details of the request. <strong>Fields:</strong></p>
<ul>
<li><code>sensitive</code> - Always set to true to ensure proper routing.</li>
<li><code>query</code> - If query logging is enabled, the text the user typed. Otherwise an
empty string.</li>
<li><code>country</code> - The country the request came from.</li>
<li><code>region</code> - The first country subdivision the request came from.</li>
<li><code>city</code> - The city the request came from.</li>
<li><code>dma</code> - A US-only location description that is larger than city and smaller
than states, but does not align to political borders.</li>
<li><code>agent</code> - The original user agent.</li>
<li><code>os_family</code> - Parsed from the user agent. One of &quot;windows&quot;, &quot;macos&quot;,
&quot;linux&quot;, &quot;ios&quot;, &quot;android&quot;, &quot;chrome os&quot;, &quot;blackberry&quot;, or &quot;other&quot;.</li>
<li><code>form_factor</code> - Parsed from the user agent. One of &quot;desktop&quot;, &quot;phone&quot;,
&quot;tablet&quot;, or &quot;other&quot;</li>
<li><code>browser</code> - The browser and possibly version detected. Either &quot;Firefox(XX)&quot;
where XX is the version, or &quot;Other&quot;.</li>
<li><code>rid</code> - The request ID.</li>
<li>WIP <code>accepts_english</code> - True if the user's Accept-Language header includes an
English locale, false otherwise.</li>
<li><code>requested_providers</code> - A comma separated list of providers requested via
the query string, or an empty string if none were requested (in which case
the default values would be used).</li>
<li><code>client_variants</code> - Any client variants sent to Merino in the query string.</li>
<li><code>session_id</code> - A UUID generated by the client for each search session.</li>
<li><code>sequence_no</code> -  A client-side event counter (0-based) that records the query
sequence within each search session.</li>
</ul>
</li>
<li>
<p><code>INFO request.summary</code> - The application request summary that follows the <a href="https://wiki.mozilla.org/Firefox/Services/Logging">MozLog</a>
convention. This log is recorded for all incoming HTTP requests except for the
suggest API endpoint.</p>
</li>
</ul>
<ul>
<li><code>ERROR dockerflow.error_endpoint</code> - The <code>__error__</code> endpoint of the server was
called. This is used to test our error reporting system. It is not a cause for
concern, unless we receive a large amount of these records, in which case some
outside service is likely malicious or misconfigured.</li>
</ul>
<h3 id="merino-middleware-logs"><a class="header" href="#merino-middleware-logs">Merino Middleware Logs</a></h3>
<h4 id="geolocation"><a class="header" href="#geolocation">Geolocation</a></h4>
<ul>
<li><code>WARNING merino.middleware.geolocation</code> - There was an error with a geolocation lookup.</li>
</ul>
<h3 id="merino-cron-tasks"><a class="header" href="#merino-cron-tasks">Merino Cron Tasks</a></h3>
<ul>
<li><code>WARNING merino.cron</code> - There was an error while executing a cron task.</li>
</ul>
<h3 id="merino-feature-flags"><a class="header" href="#merino-feature-flags">Merino Feature Flags</a></h3>
<ul>
<li><code>ERROR merino.featureflags</code> - There was an error while attempting to assign a
feature flag for a suggest API request.</li>
</ul>
<h3 id="curated-recommendations"><a class="header" href="#curated-recommendations">Curated Recommendations</a></h3>
<ul>
<li><code>ERROR merino.curated_recommendations.corpus_backends.corpus_api_backend</code> -
Failed to get timezone for scheduled surface.</li>
<li><code>WARNING merino.curated_recommendations.corpus_backends.corpus_api_backend</code> -
Retrying CorpusApiBackend after an http client exception was raised.</li>
<li><code>ERROR GcsEngagement failed to update cache: {e}</code> - unexpected exception when updating engagement.</li>
<li><code>ERROR Curated recommendations engagement size {blob.size} &gt; {self.max_size}</code> -
Max engagement blob size is exceeded. The backend will gracefully fall back to cached data or 0's.</li>
<li><code>INFO Curated recommendations engagement unchanged since {self.last_updated}.</code> -
The engagement blob was not updated since the last check. <code>last_updated</code> is expected to be
between 0 and 30 minutes.</li>
</ul>
<h2 id="metrics"><a class="header" href="#metrics">Metrics</a></h2>
<blockquote>
<p>A note on timers: Statsd timers are measured in milliseconds, and are reported
as integers (at least in Cadence). Milliseconds are often not precise enough
for the tasks we want to measure in Merino. Instead, we use generic histograms
to record microsecond times. Metrics recorded in this way should have <code>-us</code>
appended to their name, to mark the units used (since we shouldn't put the
proper unit μs in metric names).</p>
</blockquote>
<ul>
<li>
<p><code>merino.providers.initialize</code> - A timer to measure the overall initialization
duration (in ms) for <em>all</em> providers.</p>
</li>
<li>
<p><code>merino.providers.initialize.&lt;provider&gt;</code> - A timer to measure the initialization
duration (in ms) for the given <code>&lt;provider&gt;</code>.</p>
<p><strong>Example</strong>:
<code>merino.providers.initialize.adm</code></p>
</li>
<li>
<p><code>merino.&lt;http_method&gt;.&lt;url_path&gt;.status_codes.&lt;status_code&gt;</code> - A counter to measure
the status codes of an HTTP method for the <code>&lt;url_path&gt;</code>.</p>
<p><strong>Example</strong>:
<code>merino.get.api.v1.suggest.status_codes.200</code></p>
</li>
<li>
<p><code>merino.&lt;http_method&gt;.&lt;url_path&gt;.timing</code> - A timer to measure the duration (in ms)
of an HTTP method for a URL path.</p>
<p><strong>Example</strong>:
<code>merino.get.api.v1.suggest.timing</code></p>
</li>
<li>
<p><code>merino.&lt;provider_module&gt;.query</code> - A timer to measure the query duration (in ms) of
a certain suggestion provider.</p>
<p><strong>Example</strong>:
<code>merino.providers.suggest.adm.query</code></p>
</li>
<li>
<p><code>merino.&lt;provider_module&gt;.query.timeout</code> - A counter to measure the query timeouts of
a certain suggestion provider.</p>
<p><strong>Example</strong>:
<code>merino.providers.suggest.wikipedia.query.timeout</code></p>
</li>
<li>
<p><code>merino.suggestions-per.request</code> - A histogram metric to get the distribution of
suggestions per request.</p>
</li>
<li>
<p><code>merino.suggestions-per.provider.&lt;provider_module&gt;</code> - A histogram metric to get the distribution of
suggestions returned per provider (per request).</p>
<p><strong>Example</strong>:
<code>merino.suggestions-per.provider.wikipedia</code></p>
</li>
</ul>
<h3 id="accuweather"><a class="header" href="#accuweather">AccuWeather</a></h3>
<p>The weather provider records additional metrics.</p>
<ul>
<li><code>accuweather.upstream.request.&lt;request_type&gt;.get</code> - A counter to measure the number of times an upstream request to Accuweather was made.</li>
<li><code>accuweather.request.location.not_provided</code> - A counter to measure the number of times a query was send without a location being provided, and therefore unable to process a weather request. Sampled at 75%.</li>
<li><code>accuweather.request.location.dist_calculated.success</code> - A counter to measure the number of successful lat long distance calculations used to find location.</li>
<li><code>accuweather.request.location.dist_calculated.fail</code> - A counter to measure the number of failed lat long distance calculations used to find location.</li>
<li><code>merino.providers.accuweather.query.cache.fetch</code> - A timer to measure the duration (in ms) of
looking up a weather report in the cache. Sampled at 75%.</li>
<li><code>merino.providers.accuweather.query.cache.fetch.miss.locations</code> - A counter to measure the number of times weather location was not in the cache. Sampled at 75%.</li>
<li><code>merino.providers.accuweather.query.cache.fetch.miss.currentconditions</code> - A counter to measure the number of times a current conditions was not in the cache. Sampled at 75%.</li>
<li><code>merino.providers.accuweather.query.cache.fetch.miss.forecasts</code> - A counter to measure the number of times a forecast for a location was not in the cache. Sampled at 75%.</li>
<li><code>merino.providers.accuweather.query.cache.fetch.hit.{locations | currentconditions | forecasts}</code> - A counter to measure the number of times a
requested value like a location or forecast is in the cache. We don't count TTL hits explicitly, just misses. Sampled at 75%.</li>
<li><code>merino.providers.accuweather.query.backend.get</code> - A timer to measure the duration (in ms) of a
request for a weather report from the backend. This metric isn't recorded for cache hits. Sampled at 75%.</li>
<li><code>merino.providers.accuweather.query.cache.store</code> - A timer to measure the duration (in ms) of
saving a weather report from the backend to the cache. This metric isn't recorded for cache hits. Sampled at 75%.</li>
<li><code>merino.providers.accuweather.query.cache.error</code> - A counter to measure the number of times the
cache store returned an error when fetching or storing a weather report. This should be 0 in
normal operation. In case of an error, the logs will include a <code>WARNING</code> with the full error
message.</li>
<li><code>merino.providers.accuweather.skip_cities_mapping.total.size</code> - A counter to measure the total number of occurrences cities were skipped due to no location</li>
<li><code>merino.providers.accuweather.skip_cities_mapping.unique.size</code> - A counter to measure the number of unique cities that are skipped due to no location</li>
</ul>
<h3 id="curated-recommendations-1"><a class="header" href="#curated-recommendations-1">Curated Recommendations</a></h3>
<p>The following additional metrics are recorded when curated recommendations are requested.</p>
<ul>
<li><code>corpus_api.request.timing</code> -
A timer to measure the duration (in ms) of looking up a list of scheduled corpus items.</li>
<li><code>corpus_api.request.status_codes.{res.status_code}</code> -
A counter to measure the status codes of an HTTP request to the curated-corpus-api.</li>
<li><code>corpus_api.request.graphql_error</code> -
A counter to measure the number of GraphQL errors from the curated-corpus-api.</li>
<li><code>recommendation.engagement.update.timing</code> -
A timer to measure the duration (in ms) of updating the engagement data from GCS.</li>
<li><code>recommendation.engagement.size</code> - A gauge to track the size of the engagement blob on GCS.</li>
<li><code>recommendation.engagement.count</code> - A gauge to measure the total number of engagement records.</li>
<li><code>recommendation.engagement.{country}.count</code> - A gauge to measure the number of scheduled corpus
items with engagement data per country.</li>
<li><code>recommendation.engagement.{country}.clicks</code> - A gauge to measure the number of clicks per country
in our GCS engagement blob.</li>
<li><code>recommendation.engagement.{country}.impressions</code> - A gauge to measure the number of impressions
per country in our GCS engagement blob.</li>
<li><code>recommendation.engagement.last_updated</code> -
A gauge for the staleness (in seconds) of the engagement data, measured between when the data was
updated in GCS and the current time.</li>
<li><code>recommendation.prior.update.timing</code> -
A timer to measure the duration (in ms) of updating the prior data from GCS.</li>
<li><code>recommendation.prior.size</code> - A gauge to track the size of the Thompson sampling priors blob on GCS.</li>
<li><code>recommendation.prior.last_updated</code> -
A gauge for the staleness (in seconds) of the prior data, measured between when the data was
updated in GCS and the current time.</li>
</ul>
<h3 id="manifest"><a class="header" href="#manifest">Manifest</a></h3>
<p>When requesting a manifest file, we record the following metrics.</p>
<ul>
<li><code>manifest.request.get</code> - A counter for how many requests against the <code>/manifest</code> endpoint where made.</li>
<li><code>manifest.request.timing</code> - A timer for how long it took the endpoint to fulfill the request.</li>
<li><code>manifest.gcs.fetch_time</code> - A timer for how long it took to download the latest manifest file from the Google Cloud bucket.</li>
<li><code>manifest.request.no_manifest</code> - A counter to measure how many times we didn't find the latest manifest file.</li>
<li><code>manifest.request.error</code> - A counter to measure how many times we could not provide a valid JSON manifest file.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="merino-developer-guidelines-and-social-contract"><a class="header" href="#merino-developer-guidelines-and-social-contract">Merino Developer Guidelines and Social Contract</a></h1>
<p>This is an additional contractual document on top of <a href="../CONTRIBUTING.html">CONTRIBUTING</a>.</p>
<h2 id="foster-a-shared-ownership"><a class="header" href="#foster-a-shared-ownership">Foster a Shared Ownership</a></h2>
<p>Not only do Merino developers build the service together, they also share the ownership of the service. That ownership is embodied in the following responsibilities:</p>
<ul>
<li>Be responsible for the entire lifecycle of each change landed in the code base: from writing the PR and getting it merged; ensuring it goes through CI/CD and eventually deployed to production; setting up monitoring on metrics and ensuring its healthy status and the overall health of Merino.</li>
<li>Be familiar with Merino’s operation. Conduct operational reviews on a regular basis. Identify and track operational issues. Coordinate with the team(s) to close action items and resolve the identified issues.</li>
<li>Documentation. Make sure the code meets the documentation requirements (no linting errors). If a change adds/updates the API, logs or metrics, ensure the associated documentation is up to date.</li>
</ul>
<p>We commit to sharing knowledge about Merino across the team, with the long-term goal that each team member is capable of resolving incidents of Merino. Merino developers should familiarize themselves with the Mozilla Incident Response Process and the Merino Runbooks. Each individual should be able to initiate an incident response, serve as the incident handling manager, and drive it to its resolution along with other incident responders. Any issues associated with an incident should be tracked in Jira in a way the team agrees upon. For example, assigned with an ‘incident-action-items’ label.</p>
<ul>
<li>Be aware of the infrastructure costs associated with new functionality. The team should have a good understanding of the cost to run the service including logging, computing, networking, and storage costs.</li>
<li>Be mindful of work hours and the time zones of your fellow developers when scheduling meetings, deploying code, pairing on code, or collaborating in other ways. Set your work hours in Google Calendar and configure Slack to receive notifications only during those times. We encourage code deployments when there are fellow developers online to support. If you must deploy off-hours, ensure you have a peer available to approve any potential rollbacks.</li>
</ul>
<p>We are not going to grow individual Merino developers in deployment, operation, documentation, and incident responding for Merino. Rather, we’d like to foster a shared ownership with shared knowledge in every aspect of the day-to-day job for Merino.</p>
<h2 id="use-adrs-to-record-architectural-decisions"><a class="header" href="#use-adrs-to-record-architectural-decisions">Use ADRs to Record Architectural Decisions</a></h2>
<p>ADRs (Architectural Decision Record) are widely adopted by teams at Mozilla to capture important architecture decisions, including their context and consequences. Developers are encouraged to exercise the ADR process to facilitate the decision making on important subjects of the project. ADRs should be made easy to access and reference and therefore are normally checked into the source control and rendered as part of the project documentation.</p>
<h2 id="use-slo-and-error-budget-to-manage-service-risks"><a class="header" href="#use-slo-and-error-budget-to-manage-service-risks">Use SLO and Error Budget to Manage Service Risks</a></h2>
<p>We strive to build highly available and reliable services while also emphasizing rapid iteration and continuous deployment as key aspects of product development. We opt to use SLOs (Service Level Objective) and error budget for risk management. SLOs can be co-determined by the product owner(s) and the service builders &amp; operators. The error budget should be monitored and enforced by the monitoring infrastructure. Once the budget is reached, the service owners should be more reluctant or even reject to accept risky code artifacts until the budget gets reset.</p>
<h2 id="request-rra-for-new-content-integrations"><a class="header" href="#request-rra-for-new-content-integrations">Request RRA for New Content Integrations</a></h2>
<p>RRA (Rapid Risk Assessment) is the recommended process for service builders to perform a standardized lightweight risk assessment for the service or the feature of interest. Since Merino is a user-facing consumer service, we shall take extra caution for user security and the related risks. We have agreed with the Security Assurance team that we’d request an RRA (by following the RRA instructions) for every new content integration (e.g. AccuWeather) or content storage (e.g. Elasticsearch) for Merino.</p>
<h2 id="testing-for-productivity--reliability"><a class="header" href="#testing-for-productivity--reliability">Testing for Productivity &amp; Reliability</a></h2>
<p>We value testing as a mechanism of establishing feedback loops for service development, design, and release. As developers add new changes to the project, thorough and effective testing reduces uncertainty and generates short feedback loops, accelerating development, release, and regression resolution. Testing also helps reduce the potential decrease in reliability from each change. To materialize those merits for Merino, we have designed the Merino Test Strategy and fulfilled it with adequate tests. We anticipate the cross-functional team to adhere to the strategy and evolve it to better support the project over time.</p>
<h2 id="aim-for-simplicity"><a class="header" href="#aim-for-simplicity">Aim for Simplicity</a></h2>
<p>We prioritize simple and conventional solutions in all aspects of development, from system design, to API specs, to code. We prefer mature, battle-tested technologies over complex, cutting-edge alternatives. At the same time, we know that Merino can always get better, and we welcome ideas from everyone. If you’ve got a new approach in mind, share it with the team or propose an Architectural Decision Record (ADR).</p>
<h2 id="blame-free-culture"><a class="header" href="#blame-free-culture">Blame-free Culture</a></h2>
<p>While we strive to make Merino a highly reliable service, things would still go wrong regardless of how much care we take. Code errors, misconfigurations, operational glitches, to name a few. We opt for a blame-free culture to ease the mental stress when individuals are encouraged to take on more activities &amp; responsibilities, especially before they gain familiarity around the tasks. We believe that learning from mistakes and incorporating the learned experience into processes to avoid repeating the same mistakes is more constructive and useful than putting someone on center stage. With a blame-free culture and proper risk management processes in place, the average cost of failures should be more tolerable within the error budget boundary. Who would be afraid of making mistakes?</p>
<h2 id="have-fun"><a class="header" href="#have-fun">Have Fun</a></h2>
<p>Last but not least. Let’s make Merino a fun project to work with!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="developer-documentation-for-working-on-merino"><a class="header" href="#developer-documentation-for-working-on-merino">Developer documentation for working on Merino</a></h1>
<h2 id="tldr"><a class="header" href="#tldr">tl;dr</a></h2>
<p>Here are some useful commands when working on Merino.</p>
<h3 id="run-the-main-app"><a class="header" href="#run-the-main-app">Run the main app</a></h3>
<p>This project uses <a href="https://python-poetry.org/">Poetry</a> for dependency management.
See <a href="dev/./dependencies.html">dependencies</a> for how to install Poetry on your machine.</p>
<p>Install all the dependencies:</p>
<pre><code>$ poetry install
</code></pre>
<p>Run Merino:</p>
<pre><code>$ poetry run uvicorn merino.main:app --reload

# Or you can use a shortcut
$ make run
</code></pre>
<h3 id="general-commands"><a class="header" href="#general-commands">General commands</a></h3>
<pre><code class="language-shell"># List all available make commands with descriptions
$ make help

# Just like `poetry install`
$ make install

# Run linter
$ make ruff-lint

# Run format checker
$ make ruff-fmt

# Run formatter
$ make ruff-format

# Run black
$ make black

# Run bandit
$ make bandit

# Run mypy
$ make mypy

# Run all linting checks
$ make -k lint

# Run all formatters
$ make format

# Run merino-py with the auto code reloading
$ make dev

# Run merino-py without the auto code reloading
$ make run

# Run unit and integration tests and evaluate combined coverage
$ make test

# Evaluate combined unit and integration test coverage
$ make test-coverage-check

# Run unit tests
$ make unit-tests

# List fixtures in use per unit test
$ make unit-test-fixtures

# Run integration tests
$ make integration-tests

# List fixtures in use per integration test
$ make integration-test-fixtures

# Build the docker image for Merino named &quot;app:build&quot;
$ make docker-build

# Run local execution of (Locust) load tests
$ make load-tests

# Stop and remove containers and networks for load tests
$ make load-tests-clean

# Generate documents
$ make doc

# Preview the generated documents
$ make doc-preview

# Profile Merino with Scalene
$ make profile

# Run the Wikipedia CLI job
$ make wikipedia-indexer job=$JOB
</code></pre>
<h2 id="documentation"><a class="header" href="#documentation">Documentation</a></h2>
<p>You can generate documentation, both code level and book level, for Merino and
all related crates by running <code>./dev/make-all-docs.sh</code>. You'll need <a href="https://rust-lang.github.io/mdBook/">mdbook</a>
and <a href="https://github.com/badboy/mdbook-mermaid">mdbook-mermaid</a>, which you can install via:</p>
<pre><code class="language-sh">make doc-install-deps
</code></pre>
<p>If you haven't installed Rust and Cargo, you can reference the official Rust
<a href="https://doc.rust-lang.org/cargo/getting-started/installation.html">document</a>.</p>
<h2 id="local-configuration"><a class="header" href="#local-configuration">Local configuration</a></h2>
<p>The default configuration of Merino is <code>development</code>, which has human-oriented
pretty-print logging and debugging enabled. For settings that you wish to change in the
development configuration, you have two options, listed below.</p>
<blockquote>
<p>For full details, make sure to check out the documentation for
<a href="dev/../operations/configs.html">Merino's setting system (operations/configs.md)</a>.</p>
</blockquote>
<h3 id="update-the-defaults"><a class="header" href="#update-the-defaults">Update the defaults</a></h3>
<p>Dynaconf is used for all configuration management in Merino, where
values are specified in the <code>merino/configs/</code> directory in <code>.toml</code> files. Environment variables
are set for each environment as well and can be set when using the cli to launch the
Merino service.
Environment variables take precedence over the values set in the <code>.toml</code> files, so
any environment variable set will automatically override defaults. By the same token,
any config file that is pointed to will override the <code>merino/configs/default.toml</code> file.</p>
<p>If the change you want to make makes the system better for most development
tasks, consider adding it to <code>merino/configs/development.toml</code>, so that other developers
can take advantage of it. If you do so, you likely want to add validation to those settings
which needs to be added in <code>merino/config.py</code>, where the Dynaconf instance exists along
with its validators. For examples of the various config settings, look at <code>configs/default.toml</code>
and <code>merino/config.py</code> to see an example of the structure.</p>
<p>It is not advisable to put secrets in <code>configs/secrets.toml</code>.</p>
<h3 id="create-a-local-override"><a class="header" href="#create-a-local-override">Create a local override</a></h3>
<p>Dynaconf will use the specified values and environment variables in the
<code>merino/configs/default.toml</code> file. You can change the environment you
want to use as mentioned above, but for local changes to adapt to your
machine or tastes, you can put the configuration in <code>merino/configs/development.local.toml</code>.
This file doesn't exist by default, so you will have to create it.
Then simply copy from the other config files and make the adjustments
that you require. These files should however not be checked into source
control and are configured to be ignored, so long as they follow the <code>*.local.toml</code>
format. Please follow this convention and take extra care to not check them in
and only use them locally.</p>
<p>See the <a href="https://www.dynaconf.com/">Dynaconf Documentation</a> for more details.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="content-moderation-and-blocklists"><a class="header" href="#content-moderation-and-blocklists">Content Moderation and Blocklists</a></h1>
<p>This summarizes the mechanisms that block sensitive or questionable content in Merino.
Because Merino supports several providers that have a broad range of potential suggestions,
often from different sources, we require the ability to remove certain suggestions from being displayed.</p>
<p>Blocklists in Merino filter content at two distinct phases:</p>
<ol>
<li>
<p>Content that is filtered at the <em>data creation and indexing phase.</em>
Provider backends serve suggestions to the client based on matching against searched terms.
This ensures that data that could be sensitive is not available to search against since it is not indexed.
For instance, the Wikipedia provider filters categories of articles that are tagged with a matching category term in the blocklist.</p>
</li>
<li>
<p>Content that is filtered at <em>application runtime.</em>
There are instances where we want to quickly and dynamically add to block lists without re-indexing or running a job.
In this case, suggestions are compared to a static list in the code that blocks out these suggestions.</p>
</li>
</ol>
<h2 id="navigational-suggestions--top-picks"><a class="header" href="#navigational-suggestions--top-picks">Navigational Suggestions / Top Picks</a></h2>
<p>In the Navigational Suggestions provider, a blocklist is used during data creation to block specific domains of websites that we do not want to suggest.</p>
<p>The blocklist, <a href="dev//merino/jobs/navigational_suggestions/data/domain_blocklist.json"><code>domain_blocklist.json</code></a>,  is referenced during data generation of the <a href="dev//dev/top_picks.json"><code>top_picks.json</code></a> file, which is ingested by the provider backend. This ensures specific domains are not indexed for suggestions. The blocklist is loaded and an exact string comparison is made between all second-level domains and the second-level domains defined in the blocklist.</p>
<p>See <a href="dev/../operations/blocklist-nav-suggestions.html">nav-suggestions blocklist runbook</a> for more information.</p>
<h2 id="wikipedia"><a class="header" href="#wikipedia">Wikipedia</a></h2>
<p>The Wikipedia Provider does both title filtering and category filtering at the data indexing level.</p>
<p>Since the indexing jobs run periodically, we also implemented title filtering in the provider to get the blocking out sooner.</p>
<h3 id="indexer"><a class="header" href="#indexer">Indexer</a></h3>
<p>The Wikipedia Indexer Job references a remote blocklist which contains sensitive categories.
At job runtime, the indexer reads the remote blocklist and creates a set of article categories that are be excluded from indexing.</p>
<p>The article categories in the blocklist are chosen based off of analysis and best guesses of what could be considered <em>objectionable</em> content, based off of Mozilla's values and brand image.
Any modifications to the file should be done with careful consideration.</p>
<p>The indexer also blocks titles that are defined in the <code>WIKIPEDIA_TITLE_BLOCKLIST</code> in the application, which is referenced below.  Any title that matches this blocklist is excluded from indexing.</p>
<h3 id="provider"><a class="header" href="#provider">Provider</a></h3>
<p>When queried, the Wikipedia provider reads the <code>WIKIPEDIA_TITLE_BLOCKLIST</code> when creating a <code>WikipediaSuggestion</code> and if the query matches a blocked title, the suggestion is not shown to the client.</p>
<p>We have this feature because the indexing job is not run daily. Therefore, we desire having an option to rapidly add to this list should we need to block a specific article.</p>
<p>See <a href="dev/../operations/blocklist-wikipedia.html">wikipedia blocklist runbook</a> for more information.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="development-dependencies"><a class="header" href="#development-dependencies">Development Dependencies</a></h1>
<h2 id="package-dependencies"><a class="header" href="#package-dependencies">Package Dependencies</a></h2>
<p>This project uses <a href="https://python-poetry.org/">Poetry</a> for dependency management. While you can use the
vanilla virtualenv to set up the dev environment, we highly recommend to check
out <a href="https://github.com/pyenv/pyenv">pyenv</a> and <a href="https://github.com/pyenv/pyenv-virtualenv">pyenv-virtualenv</a>, as they work nicely with Poetry.
Follow the instructions to install <a href="https://github.com/pyenv/pyenv#installation">pyenv</a>, <a href="https://github.com/pyenv/pyenv-virtualenv#installation">pyenv-virtualenv</a>, and
<a href="https://python-poetry.org/docs/#installation">poetry</a>.</p>
<p>Feel free to browse the <a href="dev//pyproject.toml">pyproject.toml</a> file for a listing of dependencies
and their versions.</p>
<p>Once Poetry is installed, install all the dependencies:</p>
<pre><code>$ poetry install
</code></pre>
<p>Add packages to project via poetry</p>
<pre><code>$ poetry add &lt;package_name&gt;
</code></pre>
<p>After that you should be to run Merino as follows:</p>
<pre><code>$ poetry run uvicorn merino.main:app --reload

# Or you can fire up a poetry shell to make it shorter
$ poetry shell
$ uvicorn merino.main:app --reload
</code></pre>
<h2 id="service-dependencies"><a class="header" href="#service-dependencies">Service Dependencies</a></h2>
<p>Merino uses a Redis-based caching system, and so requires a Redis instance to
connect to.</p>
<p>To make things simple, Redis (and any future service dependencies) can be
started with Docker Compose, using the <code>docker-compose.yaml</code> file in the <code>dev/</code>
directory. Notably, this does not run any Merino components that have source
code in this repository.</p>
<pre><code class="language-shell">$ cd dev
$ docker-compose up

# Or run services in deamon mode
$ docker-compose up -d

# Stop it
$ docker-compose down


# Shortcuts are also provided
$ make docker-compose-up
$ make docker-compose-up-daemon
$ make docker-compose-down
</code></pre>
<p>Redis is listening on port 6397 and can be connected via <code>redis://localhost:6397</code>.</p>
<p>This Dockerized set up is optional. Feel free to run the dependent services by
any other means as well.</p>
<h3 id="dev-helpers"><a class="header" href="#dev-helpers">Dev Helpers</a></h3>
<p>The docker-compose setup also includes some services that can help during
development.</p>
<ul>
<li>Redis Commander, http://localhost:8081 - Explore the Redis database started
above.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="logging-and-metrics"><a class="header" href="#logging-and-metrics">Logging and Metrics</a></h1>
<p>To get data out of Merino and into observable systems, we use <em>metrics</em> and
<em>logging</em>. Each has a unique use case. Note that in general, because of the scale
we work at, adding a metric or log event in production is not free, and if we
are careless can end up costing quite a bit. Record what is needed, but don't go
over board.</p>
<p>All data collection that happens in production (logging at INFO, WARN, or ERROR
levels; and metrics) should be documented in <a href="dev/../data.html"><code>docs/data.md</code></a>.</p>
<h2 id="logging"><a class="header" href="#logging">Logging</a></h2>
<p>Merino uses <a href="https://firefox-source-docs.mozilla.org/mozbase/mozlog.html">MozLog</a> for structured logging. Logs can be recorded through the
standard Python <code>logging</code> module. Merino can output logs in various formats,
including a JSON format (MozLog) for production. A pretty, human readable format
is also provided for development and other use cases.</p>
<h3 id="types"><a class="header" href="#types">Types</a></h3>
<p>MozLog requires that all messages have a <code>type</code> value. By convention, we use
the name of the Python module, where the log record get issued, to populate this
field. For example:</p>
<pre><code class="language-py">import logging

logger = logging.getLogger(__name__)

# The `type` field of the log record will be the same as `__name__`.
logger.info(&quot;A new log message&quot;, data=extra_fields)
</code></pre>
<p>In general, the log <em>message</em> (&quot;An empty MultiProvider was created&quot;) and the log
<em>type</em> should both tell the reader what has happened. The difference is that the
message is for humans and the type is for machines.</p>
<h3 id="levels"><a class="header" href="#levels">Levels</a></h3>
<p>Tracing provides five log levels that should be familiar. This is what we mean
by them in Merino:</p>
<ul>
<li>
<p><code>CRITICAL</code> - There was a serious error indicating that the program itself may
be unable to continue running.</p>
</li>
<li>
<p><code>ERROR</code> - There was a problem, and the task was not completable. This usually
results in a 500 being sent to the user. All error logs encountered in
production are reported to Sentry and should be considered a bug. If it isn't
a bug, it shouldn't be logged as an error.</p>
</li>
<li>
<p><code>WARNING</code> - There was a problem, but the task was able to recover. This
doesn't usually affect what the user sees. Warnings are suitable for
unexpected but &quot;in-spec&quot; issues, like a sync job not returning an empty set or
using a deprecated function. These are not reported to Sentry.</p>
</li>
<li>
<p><code>INFO</code> - This is the default level of the production service. Use for logging
that something happened that isn't a problem and we care about in production.
This is the level that Merino uses for it's one-per-request logs and sync
status messages. Be careful adding new per-request logs at this level, as they
can be expensive.</p>
</li>
<li>
<p><code>DEBUG</code> - This is the default level for developers running code locally. Use
this to give insight into how the system is working, but keep in mind that
this will be on by default, so don't be too noisy. Generally this should
summarize what's happening, but not give the small details like a log line for
every iteration of a loop. Since this is off in production, there are no cost
concerns.</p>
</li>
</ul>
<h2 id="metrics-1"><a class="header" href="#metrics-1">Metrics</a></h2>
<p>Merino metrics are reported as <a href="https://www.datadoghq.com/blog/statsd/.">Statsd</a> metrics.</p>
<p>Unlike logging, the primary way that metrics reporting can cost a lot is in
<em>cardinality</em>. The number of metric IDs we have and the combination of tag
values that we supply. Often the number of individual events doesn't matter as
much, since multiple events are aggregated together.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="middlwares"><a class="header" href="#middlwares">Middlwares</a></h1>
<p>Merino leverages middleware for various functionalities such as logging, metrics,
parsing for geolocation &amp; user agent, feature flags etc. Middleware is defined
in the <code>merino/middleware</code> directory.</p>
<h2 id="caveat"><a class="header" href="#caveat">Caveat</a></h2>
<p>We currently don't implement middleware using the middleware facilities provided
by FastAPI/Starlette as they've shown significant performance overhead, preventing
Merino from achieving the SLOs required by Firefox Suggest.</p>
<p>Before those performance issues get resolved in the upstream, we will be implementing
middleware for Merino through the <a href="https://asgi.readthedocs.io/en/latest/specs/www.html">ASGI protocol</a>. You can also reference this
<a href="https://florimond.dev/en/posts/2019/08/introduction-to-asgi-async-python-web/">tutorial</a> to learn more about ASGI. See Starlette's <a href="https://www.starlette.io/middleware/">middleware</a> document
for more details about how to write pure ASGI middlewares. Specifically, we can reuse
Starlette's data structures (<code>Request</code>, <code>Headers</code>, <code>QueryParams</code> etc.) to facilitate
the implementation.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="feature-flags"><a class="header" href="#feature-flags">Feature Flags</a></h1>
<h2 id="usage"><a class="header" href="#usage">Usage</a></h2>
<p>Do you plan to release code behind a feature flag? Great! 😃</p>
<p>Your feature flag needs to be defined first. If it's already defined, go ahead.
Otherwise check the configuration section <a href="dev/feature_flags.html#configuration">below</a> before you
continue.</p>
<p>Use the following line in API endpoint code to gain access to the feature flags
object:</p>
<pre><code class="language-python">feature_flags: FeatureFlags = request.scope[ScopeKey.FEATURE_FLAGS]
</code></pre>
<p>Then check whether a certain feature flag, such as <code>example</code>, is enabled by calling:</p>
<pre><code class="language-python">if feature_flags.is_enabled(&quot;example&quot;):
    print(&quot;feature flag 'example' is enabled! 🚀&quot;)
</code></pre>
<p>When you do that, the decision (whether the feature flag is enabled or not) is
recorded and stored in a <code>dict</code> on the <code>decisions</code> attribute of the feature
flags object.</p>
<h2 id="implementation"><a class="header" href="#implementation">Implementation</a></h2>
<p>The feature flags system in Merino consists of three components:</p>
<div class="table-wrapper"><table><thead><tr><th>Description</th><th>Location</th></tr></thead><tbody>
<tr><td>A FastAPI middleware that reads the query parameter <code>sid</code> sent by the client application and sets a session ID for the current request based on that.</td><td><code>merino/middleware/featureflags.py</code></td></tr>
<tr><td>A <code>FeatureFlags</code> class which you can use to check if a certain feature flag is enabled.</td><td><code>merino/featureflags.py</code></td></tr>
<tr><td>A local directory containing static files that define and configure feature flags for Merino.</td><td><code>merino/configs/flags/</code></td></tr>
</tbody></table>
</div>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<p>Currently two bucketing schemes are supported: <code>random</code> and <code>session</code>.</p>
<h3 id="random"><a class="header" href="#random">Random</a></h3>
<p>Random does what it says on the tin. It generates a random bucketing ID for
every flag check.</p>
<h3 id="session"><a class="header" href="#session">Session</a></h3>
<p>Session bucketing uses the session ID of the request as the bucketing key so
that feature checks within a given search session would be consistent.</p>
<h3 id="fields"><a class="header" href="#fields">Fields</a></h3>
<p>Each flag defines the following fields:</p>
<pre><code class="language-toml">[default.flags.&lt;flag_name&gt;]
scheme = 'session'
enabled = 0.5
</code></pre>
<div class="table-wrapper"><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody>
<tr><td><code>scheme</code></td><td>This is the bucketing scheme for the flag. Allowed values are <code>'random'</code> and <code>'session'</code></td></tr>
<tr><td><code>enabled</code></td><td>This represents the % enabled for the flag and must be a float between <code>0</code> and <code>1</code></td></tr>
</tbody></table>
</div>
<h2 id="metrics-2"><a class="header" href="#metrics-2">Metrics</a></h2>
<p>When submitting application metrics, feature flag decisions that were made while
processing the current request up to this point are <strong>automatically</strong> added as
tags to the emitted metrics.</p>
<p>The format of these tags is:</p>
<pre><code>feature_flag.&lt;feature_flag_name&gt;
</code></pre>
<p>For more information about this see the <code>ClientMeta</code> meta class and the
<code>add_feature_flags</code> decorator in <code>merino/metrics.py</code>.</p>
<h2 id="monitoring-in-grafana"><a class="header" href="#monitoring-in-grafana">Monitoring in Grafana</a></h2>
<p>Because feature flag decisions are automatically added as tags to emitted
metrics, you can use them in your queries in Grafana. 📈</p>
<p>For example, if you want to group by decisions for a feature flag with name
<code>hello_world</code>, you can use <code>tag(feature_flag.hello_world)</code> in <code>GROUP BY</code> in
Grafana. You can also use <code>[[tag_feature_flag.hello_world]]</code> in the <code>ALIAS</code> for
panel legends.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-release-process"><a class="header" href="#the-release-process">The Release Process</a></h1>
<p>This project currently follows a <a href="https://en.wikipedia.org/wiki/Continuous_deployment">Continuous Deployment</a> process.</p>
<p>Whenever a commit is pushed to this repository's <code>main</code> branch, a CircleCI workflow is triggered
which performs code checks and runs automated tests. The workflow additionally builds a new Docker
image of the service and pushes that Docker image to the Docker Hub registry (this requires all
previous jobs to pass).</p>
<p>Pushing a new Docker image to the Docker Hub registry triggers a webhook that starts the Jenkins
deployment pipeline (the Docker image tag determines the target environment). The deployment
pipeline first deploys to the <a href="dev/../firefox.html#stage"><code>stage</code> environment</a> and subsequently to the
<a href="dev/../firefox.html#production"><code>production</code> environment</a>.</p>
<p><img src="dev/./circleci_main_workflow.jpg" alt="Activity diagram of CircleCI main-workflow" /></p>
<p>After the deployment is complete, accessing the <a href="https://stage.merino.nonprod.cloudops.mozgcp.net/__version__"><code>__version__</code> endpoint</a> will show
the commit hash of the deployed version, which will eventually match to the one of the latest commit
on the <code>main</code> branch (a node with an older version might still serve the request before it is shut
down).</p>
<h2 id="release-best-practices"><a class="header" href="#release-best-practices">Release Best Practices</a></h2>
<p>The <em>expectation</em> is that the author of the change will:</p>
<ul>
<li>merge pull requests during hours when the majority of contributors are online</li>
<li>monitor the [Merino Application &amp; Infrastructure][merino_app_info] dashboard for any anomaly</li>
</ul>
<h2 id="versioning"><a class="header" href="#versioning">Versioning</a></h2>
<p>The commit hash of the deployed code is considered its version identifier. The commit hash can be
retrieved locally via <code>git rev-parse HEAD</code>.</p>
<h2 id="load-testing"><a class="header" href="#load-testing">Load Testing</a></h2>
<p>Load testing can be performed either locally or during the deployment process. During deployment,
load tests are run against the staging environment before Merino-py is promoted to production.</p>
<p>Load tests in continuous deployment are controlled by adding a specific label to the commit message
being deployed. The format for the label is <code>[load test: (abort|skip|warn)]</code>. Typically, this label
is added to the merge commit created when a GitHub pull request is integrated.</p>
<ul>
<li><code>abort</code>: Stops the deployment if the load test fails.</li>
<li><code>skip</code>: Skips load testing entirely during deployment.</li>
<li><code>warn</code>: Proceeds with the deployment even if the load test fails, but sends a warning notification
through Slack.</li>
</ul>
<p>If no label is included in the commit message, the default behavior is to run the load test and
issue a warning if it fails.</p>
<p>For more detailed information about load testing procedures and conventions, please refer to the
<a href="https://github.com/mozilla-services/merino-py/blob/main/tests/load/README.md">Load Test README</a>.</p>
<p>Logs from load tests executed in continuous deployment are available in the <code>/data</code> volume of the
Locust master kubernetes pod.</p>
<h3 id="what-to-do-if-production-breaks"><a class="header" href="#what-to-do-if-production-breaks">What to do if production breaks?</a></h3>
<p>If your latest release causes problems and needs to be rolled back:
don't panic and follow the instructions in the <a href="dev/../operations/rollback.html">Rollback Runbook</a>.</p>
<h3 id="what-to-do-if-tests-fail-during-deployment"><a class="header" href="#what-to-do-if-tests-fail-during-deployment">What to do if tests fail during deployment?</a></h3>
<p>Please refer to <a href="dev/../operations/testfailures.html">What to do with Test Failures in CI?</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="profiling"><a class="header" href="#profiling">Profiling</a></h1>
<p>As Merino runs as a single-threaded application using the asyncio-based
framework, it would be useful for engineers to get a good understanding
about how Merino performs and where it spends time and memory doing what
tasks to serve the requests. Local profiling offers us a way to look into
those low-level details.</p>
<p>We use <a href="https://github.com/plasma-umass/scalene">Scalene</a> as the profiler to conduct the profiling for Merino.
It's very easy to use, offers extremely detailed (at the line level)
insights with much lower overhead compared to other profilers.</p>
<h2 id="usage-1"><a class="header" href="#usage-1">Usage</a></h2>
<p>To start the profiling, you can run the following to start Merino with
Scalene:</p>
<pre><code class="language-sh">$ make profile

# or you can run it directly

$ python -m scalene merino/main.py
</code></pre>
<p>Then you can send requests to Merino manually or through using other
load testing tools. Once that's done, you can terminate the Merino
application. It will automatically collect profiling outputs (CPU &amp; Memory)
and open it in your browser.</p>
<h2 id="understand-the-outputs"><a class="header" href="#understand-the-outputs">Understand the outputs</a></h2>
<p>Out of the box, Scalene provides a very intuitive web interface to display
the profiling outputs. It's organized at the file (module) level. For each
file, it shows the CPU time and average memory usage for both the line profile
and the function profile of that module. You can also click on specific columns
to sort the lines or functions accordingly.</p>
<p>For more details of how to read the outputs, you can reference Scalene's
<a href="https://github.com/plasma-umass/scalene#output">documents</a>.</p>
<p>Equipped with those insights, you can have a good understanding about the
application, identify hotspots, bottlenecks, or other findings that are
not easy to uncover by only reading the source code. And then, you can tweak
or fix those issues, test or profile it again to verify if the fix is working.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="merino-testing"><a class="header" href="#merino-testing">Merino Testing</a></h1>
<h2 id="test-strategy"><a class="header" href="#test-strategy">Test Strategy</a></h2>
<p>Merino is tested using a combination of functional and performance tests.</p>
<p>Test code resides in the <code>tests</code> directory.</p>
<p>Merino's test strategy requires that we do not go below a minimum test coverage percentage for unit
and integration tests. Load tests cannot go below a minimum performance threshold.</p>
<p>Test documentation resides in the <a href="testing/./index.html">/docs/testing/</a> directory.</p>
<p>The functional test strategy is four-tiered, composed of:</p>
<ul>
<li><a href="https://github.com/mozilla-services/merino-py/tree/main/tests/unit">unit</a> - <a href="testing/./unit-tests.html">documentation</a></li>
<li><a href="https://github.com/mozilla-services/merino-py/tree/main/tests/integration">integration</a> - <a href="testing/./integration-tests.html">documentation</a></li>
<li><a href="https://github.com/mozilla-services/merino-py/tree/main/tests/load">load</a> - <a href="testing/./load-tests.html">documentation</a></li>
</ul>
<p>See documentation and repositories in each given test area for specific details on running and
maintaining tests.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="unit-tests"><a class="header" href="#unit-tests">Unit Tests</a></h1>
<p>The unit layer is suitable for testing complex behavior at a small scale, with fine-grained control over the inputs.
Due to their narrow scope, unit tests are fundamental to thorough test coverage.</p>
<p>To execute unit tests, use: <code>make unit-tests</code></p>
<p>Unit tests are written and executed with pytest and are located in the <code>tests/unit</code> directory,
using the same organizational structure as the source code of the merino service.
Type aliases dedicated for test should be stored in the <code>types.py</code> module.
The <code>conftest.py</code> modules contain common utilities in fixtures.</p>
<p>For a breakdown of fixtures in use per test, use: <code>make unit-test-fixtures</code></p>
<h2 id="fixtures"><a class="header" href="#fixtures">Fixtures</a></h2>
<p>Available fixtures include:</p>
<h3 id="filtercaplogfixture"><a class="header" href="#filtercaplogfixture">FilterCaplogFixture</a></h3>
<p>Useful when verifying log messages, this fixture filters log records captured with
pytest's caplog by a given <code>logger_name</code>.</p>
<p><em><strong>Usage:</strong></em></p>
<pre><code class="language-python">def test_with_filter_caplog(
    caplog: LogCaptureFixture, filter_caplog: FilterCaplogFixture
) -&gt; None:
    records: list[LogRecord] = filter_caplog(caplog.records, &quot;merino.providers.suggest.adm&quot;)
</code></pre>
<p>Note: This fixture is shared with integration tests.</p>
<h3 id="suggestionrequestfixture"><a class="header" href="#suggestionrequestfixture">SuggestionRequestFixture</a></h3>
<p>For use when querying providers, this fixture creates a SuggestionRequest object with
a given <code>query</code></p>
<p><em><strong>Usage:</strong></em></p>
<pre><code class="language-python">def test_with_suggestion_request(srequest: SuggestionRequestFixture) -&gt; None:
    request: SuggestionRequest = srequest(&quot;example&quot;)
    result: list[BaseSuggestion] = await provider.query(request)
</code></pre>
<h3 id="scopefixture-receivemockfixture--sendmockfixture"><a class="header" href="#scopefixture-receivemockfixture--sendmockfixture">ScopeFixture, ReceiveMockFixture &amp; SendMockFixture</a></h3>
<p>For use when testing middleware, these fixtures initialize or mock the common Scope,
Receive and Send object dependencies.</p>
<p><em><strong>Usage:</strong></em></p>
<pre><code class="language-python">def test_middleware(scope: Scope, receive_mock: Receive, send_mock: Send) -&gt; None:
    pass
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="integration-tests"><a class="header" href="#integration-tests">Integration Tests</a></h1>
<p>The integration layer of testing allows for verification of interactions between service components,
with lower development, maintenance and execution costs compared with higher level tests.</p>
<p>To execute integration tests, make sure you have Docker installed and a docker daemon running. Then use: <code>make integration-tests</code></p>
<p>Integration tests are located in the <code>tests/integration</code> directory.
They use pytest and the FastAPI <code>TestClient</code> to send requests to specific merino endpoints and verify responses as well as other outputs, such as logs.
Tests are organized according to the API path under test.
Type aliases dedicated for test should be stored in the <code>types.py</code> module.
Fake providers created for test should be stored in the <code>fake_providers.py</code> module.
The <code>conftest.py</code> modules contain common utilities in fixtures.</p>
<p>We have also added integration tests that use <code>Docker</code> via the <code>testcontainers</code> <a href="https://testcontainers-python.readthedocs.io/en/latest/">library</a>. See fixture example below.</p>
<p>For a breakdown of fixtures in use per test, use: <code>make integration-test-fixtures</code></p>
<h2 id="fixtures-1"><a class="header" href="#fixtures-1">Fixtures</a></h2>
<p>Available fixtures include:</p>
<h3 id="filtercaplogfixture-1"><a class="header" href="#filtercaplogfixture-1">FilterCaplogFixture</a></h3>
<p><a href="testing/integration-tests.html#FilterCaplogFixture">Details</a> available in Unit Tests section</p>
<h3 id="testclientfixture"><a class="header" href="#testclientfixture">TestClientFixture</a></h3>
<p>This fixture creates an instance of the TestClient to be used in testing API calls.</p>
<p><em><strong>Usage:</strong></em></p>
<pre><code class="language-python">def test_with_test_client(client: TestClient):
    response: Response = client.get(&quot;/api/v1/endpoint&quot;)
</code></pre>
<h3 id="testclientwitheventsfixture"><a class="header" href="#testclientwitheventsfixture">TestClientWithEventsFixture</a></h3>
<p>This fixture creates an instance of the TestClient, that will trigger event handlers
(i.e. <code>startup</code> and <code>shutdown</code>) to be used in testing API calls.</p>
<p><em><strong>Usage:</strong></em></p>
<pre><code class="language-python">def test_with_test_client_with_event(client_with_events: TestClient):
    response: Response = client_with_events.get(&quot;/api/v1/endpoint&quot;)
</code></pre>
<h3 id="requestsummarylogdatafixture"><a class="header" href="#requestsummarylogdatafixture">RequestSummaryLogDataFixture</a></h3>
<p>This fixture will extract the extra log data from a captured 'request.summary'
LogRecord for verification</p>
<p><em><strong>Usage:</strong></em></p>
<pre><code class="language-python">def test_with_log_data(
    caplog: LogCaptureFixture,
    filter_caplog: FilterCaplogFixture,
    extract_request_summary_log_data: LogDataFixture
):
    records: list[LogRecord] = filter_caplog(caplog.records, &quot;request.summary&quot;)
    assert len(records) == 1

    record: LogRecord = records[0]
    log_data: dict[str, Any] = extract_request_summary_log_data(record)
    assert log_data == expected_log_data
</code></pre>
<h3 id="injectprovidersfixture--providersfixture"><a class="header" href="#injectprovidersfixture--providersfixture">InjectProvidersFixture &amp; ProvidersFixture</a></h3>
<p>These fixture will setup and teardown given providers.</p>
<p><em><strong>Usage:</strong></em></p>
<p>If specifying providers for a module:</p>
<pre><code class="language-python">@pytest.fixture(name=&quot;providers&quot;)
def fixture_providers() -&gt; Providers:
    return {&quot;test-provider&quot;: TestProvider()}
</code></pre>
<p>If specifying providers for a test:</p>
<pre><code class="language-python">@pytest.mark.parametrize(&quot;providers&quot;, [{&quot;test-provider&quot;: TestProvider()}])
def test_with_provider() -&gt; None:
    pass
</code></pre>
<h3 id="setupprovidersfixture"><a class="header" href="#setupprovidersfixture">SetupProvidersFixture</a></h3>
<p>This fixture sets application provider dependency overrides.</p>
<p><em><strong>Usage:</strong></em></p>
<pre><code class="language-python">def test_with_setup_providers(setup_providers: SetupProvidersFixture):
    providers: dict[str, BaseProvider] = {&quot;test-provider&quot;: TestProvider()}
    setup_providers(providers)
</code></pre>
<h3 id="teardownprovidersfixture"><a class="header" href="#teardownprovidersfixture">TeardownProvidersFixture</a></h3>
<p>This fixture resets application provider dependency overrides and is often used in
teardown fixtures.</p>
<p><em><strong>Usage:</strong></em></p>
<pre><code class="language-python">@pytest.fixture(autouse=True)
def teardown(teardown_providers: TeardownProvidersFixture):
    yield
    teardown_providers()
</code></pre>
<h3 id="testcontainersfixture"><a class="header" href="#testcontainersfixture">TestcontainersFixture</a></h3>
<p>See <code>tests/integration/jobs/navigational_suggestions/test_domain_metadata_uploader.py</code> for a detailed example.</p>
<p>This is a lightweight example on how to set up a docker container for your integration tests.</p>
<p><em><strong>Usage:</strong></em></p>
<pre><code class="language-python">@pytest.fixture(scope=&quot;module&quot;)
def your_docker_container() -&gt; DockerContainer:
    os.environ.setdefault(&quot;STORAGE_EMULATOR_HOST&quot;, &quot;http://localhost:4443&quot;)

    container = (
        DockerContainer(&quot;your-docker-image&quot;)
        .with_command(&quot;-scheme http&quot;)
        .with_bind_ports(4443, 4443)
    ).start()

    # wait for the container to start and emit logs
    delay = wait_for_logs(container, &quot;server started at&quot;)
    port = container.get_exposed_port(4443)

    yield container

    container.stop()
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="merino-load-locust-tests"><a class="header" href="#merino-load-locust-tests">Merino Load (Locust) Tests</a></h1>
<p>This documentation describes the load tests for Merino.
This test framework uses IP2Location LITE data available from https://lite.ip2location.com</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>The tests in the <code>tests/load</code> directory spawn multiple HTTP clients that consume Merino's API,
in order to simulate real-world load on the Merino infrastructure.
These tests use the Locust framework and are triggered at the discretion of the Merino Engineering Team.</p>
<h2 id="related-documentation"><a class="header" href="#related-documentation">Related Documentation</a></h2>
<ul>
<li><a href="https://docs.google.com/document/d/1v7LDXENPZg37KXeNcznEZKNZ8rQlOhNbsHprFyMXHhs/edit?usp=sharing">Merino Load Test Plan</a></li>
<li><a href="https://docs.google.com/document/d/1BGNhKuclUH40Bit9KxYWLiv_N_VnE66uxi9pBFbRWbg/edit">Merino Load Test History</a></li>
<li><a href="https://docs.google.com/spreadsheets/d/1SAO3QYIrbxDRxzmYIab-ebZXA1dF06W1lT4I1h2R3a8/edit?usp=sharing">Merino Load Test Spreadsheet</a></li>
</ul>
<h2 id="local-execution"><a class="header" href="#local-execution">Local Execution</a></h2>
<p>Note that if you make changes to the load test code, you must stop and remove the Docker containers and networks for changes to reflect.
Do this by running <code>make load-tests-clean</code>.</p>
<p>Follow the steps bellow to execute the load tests locally:</p>
<h3 id="setup-environment"><a class="header" href="#setup-environment">Setup Environment</a></h3>
<h4 id="1-configure-environment-variables"><a class="header" href="#1-configure-environment-variables">1. Configure Environment Variables</a></h4>
<p>The following environment variables as well as
<a href="https://docs.locust.io/en/stable/configuration.html#environment-variables">Locust environment variables</a> can be set in
<code>tests\load\docker-compose.yml</code>.
Make sure any required API key is added but then not checked into source control.</p>
<p><strong>WARNING</strong>: if the <code>WIKIPEDIA__ES_API_KEY</code> is missing, the load tests will not execute.</p>
<div class="table-wrapper"><table><thead><tr><th>Environment Variable</th><th>Node(s)</th><th>Description</th></tr></thead><tbody>
<tr><td>LOAD_TESTS__LOGGING_LEVEL</td><td>master &amp; worker</td><td>Level for the logger in the load tests as an int (<code>10</code> for <code>DEBUG</code>, <code>20</code> for <code>INFO</code> etc.)</td></tr>
<tr><td>MERINO_REMOTE_SETTINGS__SERVER</td><td>master &amp; worker</td><td>Server URL of the Kinto instance containing suggestions</td></tr>
<tr><td>MERINO_REMOTE_SETTINGS__BUCKET</td><td>master &amp; worker</td><td>Kinto bucket with the suggestions</td></tr>
<tr><td>MERINO_REMOTE_SETTINGS__COLLECTION</td><td>master &amp; worker</td><td>Kinto collection with the suggestions</td></tr>
<tr><td>MERINO_PROVIDERS__TOP_PICKS__TOP_PICKS_FILE_PATH</td><td>master &amp; worker</td><td>The minimum character limit set for long domain suggestion indexing</td></tr>
<tr><td>MERINO_PROVIDERS__TOP_PICKS__QUERY_CHAR_LIMIT</td><td>master &amp; worker</td><td>The minimum character limit set for short domain suggestion indexing</td></tr>
<tr><td>MERINO_PROVIDERS__TOP_PICKS__FIREFOX_CHAR_LIMIT</td><td>master &amp; worker</td><td>File path to the json file of domains</td></tr>
<tr><td>MERINO_PROVIDERS__WIKIPEDIA__ES_API_KEY</td><td>master &amp; worker</td><td>The base64 key used to authenticate on the Elasticsearch cluster specified by es_cloud_id</td></tr>
<tr><td>MERINO_PROVIDERS__WIKIPEDIA__ES_URL</td><td>master &amp; worker</td><td>The Cloud ID of the Elasticsearch cluster</td></tr>
<tr><td>MERINO_PROVIDERS__WIKIPEDIA__ES_INDEX</td><td>master &amp; worker</td><td>The index identifier of Wikipedia in Elasticsearch</td></tr>
</tbody></table>
</div>
<h4 id="2-host-locust-via-docker"><a class="header" href="#2-host-locust-via-docker">2. Host Locust via Docker</a></h4>
<p>Execute the following from the repository root:</p>
<pre><code class="language-shell">make load-tests
</code></pre>
<h4 id="3-optional-host-merino-locally"><a class="header" href="#3-optional-host-merino-locally">3. (Optional) Host Merino Locally</a></h4>
<p>Use one of the following commands to host Merino locally. Execute the following from the
repository root:</p>
<ul>
<li>Option 1: Use the local development instance
<pre><code class="language-shell">make dev
</code></pre>
</li>
<li>Option 2: Use the profiler instance
<pre><code class="language-shell">make profile
</code></pre>
</li>
<li>Option 3: Use the Docker instance
<pre><code class="language-shell">make docker-build &amp;&amp; docker run -p 8000:8000 app:build
</code></pre>
</li>
</ul>
<h3 id="run-test-session"><a class="header" href="#run-test-session">Run Test Session</a></h3>
<h4 id="1-start-load-test"><a class="header" href="#1-start-load-test">1. Start Load Test</a></h4>
<ul>
<li>In a browser navigate to <code>http://localhost:8089/</code></li>
<li>Set up the load test parameters:
<ul>
<li>Option 1: Select the <code>MerinoSmokeLoadTestShape</code> or <code>MerinoAverageLoadTestShape</code>
<ul>
<li>These options have pre-defined settings</li>
</ul>
</li>
<li>Option 2: Select the <code>Default</code> load test shape with the following recommended settings:
<ul>
<li>Number of users: 25</li>
<li>Spawn rate: 1</li>
<li>Host: 'https://stagepy.merino.nonprod.cloudops.mozgcp.net'
<ul>
<li>Set host to 'http://host.docker.internal:8000' to test against a local instance of Merino</li>
</ul>
</li>
<li>Duration (Optional): 10m</li>
</ul>
</li>
</ul>
</li>
<li>Select &quot;Start Swarming&quot;</li>
</ul>
<h4 id="2-stop-load-test"><a class="header" href="#2-stop-load-test">2. Stop Load Test</a></h4>
<p>Select the 'Stop' button in the top right hand corner of the Locust UI, after the
desired test duration has elapsed. If the 'Run time' is set in step 1, the load test
will stop automatically.</p>
<h4 id="3-analyse-results"><a class="header" href="#3-analyse-results">3. Analyse Results</a></h4>
<ul>
<li>See <a href="testing/load-tests.html#3-analyse-results-1">Distributed GCP Execution (Manual Trigger) - Analyse Results</a></li>
<li>Only client-side measures, provided by Locust, are available when executing against a
local instance of Merino.</li>
</ul>
<h3 id="clean-up-environment"><a class="header" href="#clean-up-environment">Clean-up Environment</a></h3>
<h4 id="1-remove-load-test-docker-containers"><a class="header" href="#1-remove-load-test-docker-containers">1. Remove Load Test Docker Containers</a></h4>
<p>Execute the following from the repository root:</p>
<pre><code class="language-shell">make load-tests-clean
</code></pre>
<h2 id="distributed-gcp-execution---manual-trigger"><a class="header" href="#distributed-gcp-execution---manual-trigger">Distributed GCP Execution - Manual Trigger</a></h2>
<p>Follow the steps bellow to execute the distributed load tests on GCP with a manual trigger:</p>
<h3 id="setup-environment-1"><a class="header" href="#setup-environment-1">Setup Environment</a></h3>
<h4 id="1-start-a-gcp-cloud-shell"><a class="header" href="#1-start-a-gcp-cloud-shell">1. Start a GCP Cloud Shell</a></h4>
<p>The load tests can be executed from the <a href="https://console.cloud.google.com/home/dashboard?q=search&amp;referrer=search&amp;project=spheric-keel-331521&amp;cloudshell=false">contextual-services-test-eng cloud shell</a>.</p>
<h4 id="2-configure-the-bash-script"><a class="header" href="#2-configure-the-bash-script">2. Configure the Bash Script</a></h4>
<ul>
<li>The <code>setup_k8s.sh</code> file, located in the <code>tests\load</code> directory, contains shell
commands to <strong>create</strong> a GKE cluster, <strong>setup</strong> an existing GKE cluster or <strong>delete</strong>
a GKE cluster
<ul>
<li>Modify the script to include the MERINO_PROVIDERS__WIKIPEDIA__ES_API_KEY
environment variables</li>
<li>Execute the following from the root directory, to make the file executable:
<pre><code class="language-shell">chmod +x tests/load/setup_k8s.sh
</code></pre>
</li>
</ul>
</li>
</ul>
<h4 id="3-create-the-gcp-cluster"><a class="header" href="#3-create-the-gcp-cluster">3. Create the GCP Cluster</a></h4>
<ul>
<li>Execute the <code>setup_k8s.sh</code> file and select the <strong>create</strong> option, in order to
initiate the process of creating a cluster, setting up the env variables and
building the docker image. Choose smoke or average depending on the type
of load test required.
<pre><code class="language-shell">./tests/load/setup_k8s.sh create [smoke|average]
</code></pre>
<ul>
<li>Smoke - The smoke load test verifies the system's performance under minimal load. The test is
run for a short period, possibly in CD, to ensure the system is working correctly.</li>
<li>Average - The average load test measures the system's performance under standard operational conditions.
The test is meant to reflect an ordinary day in production.</li>
</ul>
</li>
<li>The cluster creation process will take some time. It is considered complete, once
an external IP is assigned to the <code>locust_master</code> node. Monitor the assignment via
a watch loop:
<pre><code class="language-bash">kubectl get svc locust-master --watch
</code></pre>
</li>
<li>The number of workers is defaulted to 5, but can be modified with the
<code>kubectl scale</code> command. Example (10 workers):
<pre><code class="language-bash">kubectl scale deployment/locust-worker --replicas=10
</code></pre>
</li>
<li>To apply new changes to an existing GCP Cluster, execute the <code>setup_k8s.sh</code> file and select the
<strong>setup</strong> option.
<ul>
<li>This option will consider the local commit history, creating new containers and
deploying them (see <a href="https://console.cloud.google.com/artifacts/docker/spheric-keel-331521/us-west1/locust-merino?project=spheric-keel-331521">Artifact Registry</a>)</li>
</ul>
</li>
</ul>
<h3 id="run-test-session-1"><a class="header" href="#run-test-session-1">Run Test Session</a></h3>
<h4 id="1-start-load-test-1"><a class="header" href="#1-start-load-test-1">1. Start Load Test</a></h4>
<ul>
<li>
<p>In a browser navigate to <code>http://$EXTERNAL_IP:8089</code></p>
<p>This url can be generated via command</p>
<pre><code class="language-bash">EXTERNAL_IP=$(kubectl get svc locust-master -o jsonpath=&quot;{.status.loadBalancer.ingress[0].ip}&quot;)
echo http://$EXTERNAL_IP:8089
</code></pre>
</li>
<li>
<p>Select the <code>MerinoSmokeLoadTestShape</code>, this option has pre-defined settings and will last 5 minutes</p>
</li>
<li>
<p>Select &quot;Start Swarming&quot;</p>
</li>
</ul>
<h4 id="2-stop-load-test-1"><a class="header" href="#2-stop-load-test-1">2. Stop Load Test</a></h4>
<p>Select the 'Stop' button in the top right hand corner of the Locust UI, after the
desired test duration has elapsed. If the 'Run time' is set in step 1, the load test
will stop automatically.</p>
<h4 id="3-analyse-results-1"><a class="header" href="#3-analyse-results-1">3. Analyse Results</a></h4>
<p><strong>RPS</strong></p>
<ul>
<li>The request-per-second load target for Merino is <code>1500</code></li>
<li>Locust reports client-side RPS via the &quot;merino_stats.csv&quot; file and the UI
(under the &quot;Statistics&quot; tab or the &quot;Charts&quot; tab)</li>
<li><a href="https://earthangel-b40313e5.influxcloud.net/d/rQAfYKIVk/merino-py-application-and-infrastructure?orgId=1&amp;refresh=1m&amp;var-environment=stagepy">Grafana</a> reports the server-side RPS via the
&quot;HTTP requests per second per country&quot; chart</li>
</ul>
<p><strong>HTTP Request Failures</strong></p>
<ul>
<li>The number of responses with errors (5xx response codes) should be <code>0</code></li>
<li>Locust reports Failures via the &quot;merino_failures.csv&quot; file and the UI
(under the &quot;Failures&quot; tab or the &quot;Charts&quot; tab)</li>
<li><a href="https://earthangel-b40313e5.influxcloud.net/d/rQAfYKIVk/merino-py-application-and-infrastructure?orgId=1&amp;refresh=1m&amp;var-environment=stagepy">Grafana</a> reports Failures via the &quot;HTTP Response codes&quot; chart and the
&quot;HTTP 5xx error rate&quot; chart</li>
</ul>
<p><strong>Exceptions</strong></p>
<ul>
<li>The number of exceptions raised by the test framework should be <code>0</code></li>
<li>Locust reports Exceptions via the &quot;merino_exceptions.csv&quot; file and the UI
(under the &quot;Exceptions&quot; tab)</li>
</ul>
<p><strong>Latency</strong></p>
<ul>
<li>The HTTP client-side response time (aka request duration) for 95 percent of users
is required to be 200ms or less (<code>p95 &lt;= 200ms</code>), excluding weather requests</li>
<li>Locust reports client-side latency via the &quot;merino_stats.csv&quot; file and the UI
(under the &quot;Statistics&quot; tab or the &quot;Charts&quot; tab)
<ul>
<li><em>Warning!</em> A Locust worker with too many users will bottleneck RPS and inflate
client-side latency measures. Locust reports worker CPU and memory usage metrics via
the UI (under the &quot;Workers&quot; tab)</li>
</ul>
</li>
<li><a href="https://earthangel-b40313e5.influxcloud.net/d/rQAfYKIVk/merino-py-application-and-infrastructure?orgId=1&amp;refresh=1m&amp;var-environment=stagepy">Grafana</a> reports server-side latency via the &quot;p95 latency&quot; chart</li>
</ul>
<p><strong>Resource Consumption</strong></p>
<ul>
<li>To conserve costs, resource allocation must be kept to a minimum. It is expected that
container, CPU and memory usage should trend consistently between load test runs.</li>
<li><a href="https://earthangel-b40313e5.influxcloud.net/d/rQAfYKIVk/merino-py-application-and-infrastructure?orgId=1&amp;refresh=1m&amp;var-environment=stagepy">Grafana</a> reports metrics on resources via the &quot;Container Count&quot;,
&quot;CPU usage time sum&quot; and &quot;Memory usage sum&quot; charts</li>
</ul>
<h4 id="4-report-results"><a class="header" href="#4-report-results">4. Report Results</a></h4>
<ul>
<li>Results should be recorded in the <a href="https://docs.google.com/spreadsheets/d/1SAO3QYIrbxDRxzmYIab-ebZXA1dF06W1lT4I1h2R3a8/edit?usp=sharing">Merino Load Test Spreadsheet</a></li>
<li>Optionally, the Locust reports can be saved and linked in the spreadsheet:
<ul>
<li>Download the results via the Locust UI or via command:
<pre><code class="language-bash">kubectl cp &lt;master-pod-name&gt;:/home/locust/merino_stats.csv merino_stats.csv
kubectl cp &lt;master-pod-name&gt;:/home/locust/merino_exceptions.csv merino_exceptions.csv
kubectl cp &lt;master-pod-name&gt;:/home/locust/merino_failures.csv merino_failures.csv
</code></pre>
The <code>master-pod-name</code> can be found at the top of the pod list:
<pre><code class="language-bash">kubectl get pods -o wide
</code></pre>
</li>
<li>Upload the files to the <a href="https://drive.google.com/drive/folders/1rvCpmwGuLt4COH6Zw6vSyu_019_sB3Ux">ConServ</a> drive and record the links in the
spreadsheet</li>
</ul>
</li>
</ul>
<h3 id="clean-up-environment-1"><a class="header" href="#clean-up-environment-1">Clean-up Environment</a></h3>
<h4 id="1-delete-the-gcp-cluster"><a class="header" href="#1-delete-the-gcp-cluster">1. Delete the GCP Cluster</a></h4>
<p>Execute the <code>setup_k8s.sh</code> file and select the <strong>delete</strong> option</p>
<pre><code class="language-shell">./tests/load/setup_k8s.sh
</code></pre>
<h2 id="distributed-gcp-execution---ci-trigger"><a class="header" href="#distributed-gcp-execution---ci-trigger">Distributed GCP Execution - CI Trigger</a></h2>
<p>The load tests are triggered in CI via <a href="https://github.com/mozilla-services/cloudops-infra/blob/master/projects/merino/Jenkinsfile-stage-py">Jenkins</a>, which has a command overriding
the load test Dockerfile entrypoint.</p>
<p>Follow the steps below to execute the distributed load tests on GCP with a CI trigger:</p>
<h3 id="run-test-session-2"><a class="header" href="#run-test-session-2">Run Test Session</a></h3>
<h4 id="1-execute-load-test"><a class="header" href="#1-execute-load-test">1. Execute Load Test</a></h4>
<p>To modify the load testing behavior, you must include a label in your Git commit. This must be the
merge commit on the main branch, since only the most recent commit is checked for the label. The
label format is: <code>[load test: (abort|skip|warn)]</code>. Take careful note of correct syntax and spacing
within the label. There are three options for load tests: <code>abort</code>, <code>skip</code>, and <code>warn</code>:</p>
<ul>
<li>The <code>abort</code> label will prevent a prod deployment if the load test fails<br />
Ex. <code>feat: Add feature ABC [load test: abort].</code></li>
<li>The <code>skip</code> label will bypass load testing entirely during deployment<br />
Ex. <code>feat: Add feature LMN [load test: skip].</code></li>
<li>The <code>warn</code> label will output a Slack warning if the load test fails but still allow for the
production deployment<br />
Ex. <code>feat: Add feature XYZ [load test: warn].</code></li>
</ul>
<p>If no label is included in the commit message, the load test will be executed with the <code>warn</code>
action.</p>
<p>The commit tag signals load test instructions to Jenkins by modifying the Docker image tag. The
Jenkins deployment workflow first deploys to <code>stage</code> and then runs load tests if requested. The
Docker image tag passed to Jenkins appears as follows:
<code>^(?P&lt;environment&gt;stage|prod)(?:-(?P&lt;task&gt;\w+)-(?P&lt;action&gt;abort|skip|warn))?-(?P&lt;commit&gt;[a-z0-9]+)$</code></p>
<h4 id="2-analyse-results"><a class="header" href="#2-analyse-results">2. Analyse Results</a></h4>
<p>See <a href="testing/load-tests.html#3-analyse-results-1">Distributed GCP Execution (Manual Trigger) - Analyse Results</a></p>
<h4 id="3-report-results"><a class="header" href="#3-report-results">3. Report Results</a></h4>
<ul>
<li>Optionally, results can be recorded in the <a href="https://docs.google.com/spreadsheets/d/1SAO3QYIrbxDRxzmYIab-ebZXA1dF06W1lT4I1h2R3a8/edit?usp=sharing">Merino Load Test Spreadsheet</a>. It
is recommended to do so if unusual behavior is observed during load test execution or if the load
tests fail.</li>
<li>The Locust reports can be saved and linked in the spreadsheet. The results are persisted in the
<code>/data</code> directory of the <code>locust-master-0</code> pod in the <code>locust-master</code> k8s cluster in the GCP
project of <code>merino-nonprod</code>. To access the Locust logs:
<ul>
<li>Open a cloud shell in the <a href="https://console.cloud.google.com/kubernetes/list/overview?project=moz-fx-merino-nonprod-ee93">Merino stage environment</a></li>
<li>Authenticate by executing the following command:
<pre><code class="language-shell">  gcloud container clusters get-credentials merino-nonprod-v1 \
    --region us-west1 --project moz-fx-merino-nonprod-ee93
</code></pre>
</li>
<li>Identify the log files needed in the Kubernetes pod by executing the following command, which
lists the log files along with file creation timestamp when the test was performed. The
<code>{run-id}</code> uniquely identifies each load test run:
<pre><code class="language-bash">  kubectl exec -n locust-merino locust-master-0 -- ls -al /data/
</code></pre>
</li>
<li>Download the results via the Locust UI or via command:
<pre><code class="language-bash">kubectl -n locust-merino cp locust-master-0:/data/{run-id}-merino_stats.csv merino_stats.csv
kubectl -n locust-merino cp locust-master-0:/data/{run-id}-merino_exceptions.csv merino_exceptions.csv
kubectl -n locust-merino cp locust-master-0:/data/{run-id}-merino_failures.csv merino_failures.csv
</code></pre>
</li>
<li>Upload the files to the <a href="https://drive.google.com/drive/folders/1rvCpmwGuLt4COH6Zw6vSyu_019_sB3Ux">ConServ</a> drive and record the links in the
spreadsheet</li>
</ul>
</li>
</ul>
<h2 id="calibration"><a class="header" href="#calibration">Calibration</a></h2>
<p>Following the addition of new features, such as a Locust Task or Locust User, or
environmental changes, such as node size or the upgrade of a major dependency like the
python version image, it may be necessary to re-establish the recommended parameters of
the performance test.</p>
<div class="table-wrapper"><table><thead><tr><th>Parameter</th><th>Description</th></tr></thead><tbody>
<tr><td><code>WAIT TIME</code></td><td>- Changing this cadence will increase or decrease the number of channel subscriptions and notifications sent by a MerinoUser. <br/>- The default is currently in use for the MerinoUser class.</td></tr>
<tr><td><code>TASK WEIGHT</code></td><td>- Changing this weight impacts the probability of a task being chosen for execution. <br/>- This value is hardcoded in the task decorators of the MerinoUser class.</td></tr>
<tr><td><code>USERS_PER_WORKER</code></td><td>- This value should be set to the maximum number of users a Locust worker can support given CPU and memory constraints. <br/>- This value is hardcoded in the LoadTestShape classes.</td></tr>
<tr><td><code>WORKER_COUNT</code></td><td>- This value is derived by dividing the total number of users needed for the performance test by the <code>USERS_PER_WORKER</code>. <br>- This value is hardcoded in the LoadTestShape classes and the setup_k8s.sh script.</td></tr>
</tbody></table>
</div>
<ul>
<li>Locust documentation is available for [WAIT TIME][13] and [TASK WEIGHT][14]</li>
</ul>
<h2 id="calibrating-for-users_per_worker"><a class="header" href="#calibrating-for-users_per_worker">Calibrating for USERS_PER_WORKER</a></h2>
<p>This process is used to determine the number of users that a Locust worker can support.</p>
<h3 id="setup-environment-2"><a class="header" href="#setup-environment-2">Setup Environment</a></h3>
<h4 id="1-start-a-gcp-cloud-shell-1"><a class="header" href="#1-start-a-gcp-cloud-shell-1">1. Start a GCP Cloud Shell</a></h4>
<p>The load tests can be executed from the <a href="https://console.cloud.google.com/home/dashboard?q=search&amp;referrer=search&amp;project=spheric-keel-331521&amp;cloudshell=false">contextual-services-test-eng cloud shell</a>.
If executing a load test for the first time, the git merino-py repository will need to
be cloned locally.</p>
<h4 id="2-configure-the-bash-script-1"><a class="header" href="#2-configure-the-bash-script-1">2. Configure the Bash Script</a></h4>
<ul>
<li>The <code>setup_k8s.sh</code> file, located in the <code>tests\load</code> directory, contains
shell commands to <strong>create</strong> a GKE cluster, <strong>setup</strong> an existing GKE cluster or
<strong>delete</strong> a GKE cluster
<ul>
<li>Execute the following from the root directory, to make the file executable:
<pre><code class="language-shell">chmod +x tests/load/setup_k8s.sh
</code></pre>
</li>
</ul>
</li>
</ul>
<h4 id="3-create-the-gcp-cluster-1"><a class="header" href="#3-create-the-gcp-cluster-1">3. Create the GCP Cluster</a></h4>
<ul>
<li>In the <code>setup_k8s.sh</code> script, modify the <code>WORKER_COUNT</code> variable to equal <code>1</code></li>
<li>Execute the <code>setup_k8s.sh</code> file from the root directory and select the <strong>create</strong>
option, in order to initiate the process of creating a cluster, setting up the env
variables and building the docker image. Choose smoke or average depending on the type
of load test required.
<pre><code class="language-shell">./tests/load/setup_k8s.sh create [smoke|average]
</code></pre>
</li>
<li>The cluster creation process will take some time. It is considered complete, once
an external IP is assigned to the <code>locust_master</code> node. Monitor the assignment via
a watch loop:
<pre><code class="language-bash">kubectl get svc locust-master --watch
</code></pre>
</li>
</ul>
<h3 id="calibrate"><a class="header" href="#calibrate">Calibrate</a></h3>
<p>Repeat steps 1 to 3, using a process of elimination, such as the bisection method, to
determine the maximum <code>USERS_PER_WORKER</code>. The load tests are considered optimized when
CPU and memory resources are maximally utilized. This step is meant to determine the
maximum user count that a node can accommodate by observing CPU and memory usage while
steadily increasing or decreasing the user count. You can monitor the CPU percentage in
the Locust UI but also in the Kubernetes engine Workloads tab where both memory and CPU
are visualized on charts.</p>
<h4 id="1-start-load-test-2"><a class="header" href="#1-start-load-test-2">1. Start Load Test</a></h4>
<ul>
<li>In a browser navigate to <code>http://$EXTERNAL_IP:8089</code>
This url can be generated via command
<pre><code class="language-bash">EXTERNAL_IP=$(kubectl get svc locust-master -o jsonpath=&quot;{.status.loadBalancer.ingress[0].ip}&quot;)
echo http://$EXTERNAL_IP:8089
</code></pre>
</li>
<li>Set up the load test parameters:
<ul>
<li>ShapeClass: Default</li>
<li>UserClasses: MerinoUser</li>
<li>Number of users: USERS_PER_WORKER (Consult the <a href="https://docs.google.com/spreadsheets/d/1SAO3QYIrbxDRxzmYIab-ebZXA1dF06W1lT4I1h2R3a8/edit?usp=sharing">Merino_spreadsheet</a> to determine a starting point)</li>
<li>Ramp up: RAMP_UP (RAMP_UP = 5/USERS_PER_WORKER)</li>
<li>Host: 'https://stagepy.merino.nonprod.cloudops.mozgcp.net'</li>
<li>Duration (Optional): 600s</li>
</ul>
</li>
<li>Select &quot;Start Swarm&quot;</li>
</ul>
<h4 id="2-stop-load-test-2"><a class="header" href="#2-stop-load-test-2">2. Stop Load Test</a></h4>
<p>Select the 'Stop' button in the top right hand corner of the Locust UI, after the
desired test duration has elapsed. If the 'Run time' or 'Duration' is set in step 1,
the load test will stop automatically.</p>
<h4 id="3-analyse-results-2"><a class="header" href="#3-analyse-results-2">3. Analyse Results</a></h4>
<p><strong>CPU and Memory Resource Graphs</strong></p>
<ul>
<li>CPU and Memory usage should be less than 90% of the available capacity
<ul>
<li>CPU and Memory Resources can be observed in
<a href="https://console.cloud.google.com/kubernetes/list/overview?cloudshell=false&amp;project=spheric-keel-331521">Google Cloud &gt; Kubernetes Engine &gt; Workloads</a></li>
</ul>
</li>
</ul>
<p><strong>Log Errors or Warnings</strong></p>
<ul>
<li>Locust will emit errors or warnings if high CPU or memory usage occurs during the
execution of a load test. The presence of these logs is a strong indication that the
<code>USERS_PER_WORKER</code> count is too high</li>
</ul>
<h4 id="4-report-results-1"><a class="header" href="#4-report-results-1">4. Report Results</a></h4>
<p>See <a href="testing/load-tests.html#3-analyse-results-1">Distributed GCP Execution (Manual Trigger) - Analyse Results</a></p>
<h4 id="5-update-shape-and-script-values"><a class="header" href="#5-update-shape-and-script-values">5. Update Shape and Script Values</a></h4>
<ul>
<li><code>WORKER_COUNT = MAX_USERS/USERS_PER_WORKER</code>
<ul>
<li>If <code>MAX_USERS</code> is unknown, calibrate to determine <code>WORKER_COUNT</code></li>
</ul>
</li>
<li>Update the <code>USERS_PER_WORKER</code> and <code>WORKER_COUNT</code> values in the following files:
<ul>
<li><code>\tests\load\locustfiles\smoke_load.py</code> or <code>\tests\load\locustfiles\average_load.py</code></li>
<li>\tests\load\setup_k8s.sh</li>
</ul>
</li>
</ul>
<h3 id="clean-up-environment-2"><a class="header" href="#clean-up-environment-2">Clean-up Environment</a></h3>
<p>See <a href="testing/load-tests.html#clean-up-environment">Distributed GCP Execution (Manual Trigger) - Clean-up Environment</a></p>
<h2 id="calibrating-for-worker_count"><a class="header" href="#calibrating-for-worker_count">Calibrating for WORKER_COUNT</a></h2>
<p>This process is used to determine the number of Locust workers required in order to
generate sufficient load for a test given a SHAPE_CLASS.</p>
<h3 id="setup-environment-3"><a class="header" href="#setup-environment-3">Setup Environment</a></h3>
<ul>
<li>See <a href="testing/load-tests.html#setup-environment-1">Distributed GCP Execution (Manual Trigger) - Setup Environment</a></li>
<li>Note that in the <code>setup_k8s.sh</code> the maximum number of nodes is set using the
<code>total-max-nodes</code> google cloud option. It may need to be increased if the number of
workers can't be supported by the cluster.</li>
</ul>
<h3 id="calibrate-1"><a class="header" href="#calibrate-1">Calibrate</a></h3>
<p>Repeat steps 1 to 4, using a process of elimination, such as the bisection method, to
determine the maximum <code>WORKER_COUNT</code>. The tests are considered optimized when they
generate the minimum load required to cause node scaling in the the Merino-py Stage
environment. You can monitor the Merino-py pod counts on <a href="https://earthangel-b40313e5.influxcloud.net/d/rQAfYKIVk/merino-py-application-and-infrastructure?orgId=1&amp;refresh=1m&amp;var-environment=stagepy">Grafana</a>.</p>
<h4 id="1-update-shape-and-script-values"><a class="header" href="#1-update-shape-and-script-values">1. Update Shape and Script Values</a></h4>
<ul>
<li>Update the <code>WORKER_COUNT</code> values in the following files:
<ul>
<li><code>\tests\load\locustfiles\smoke_load.py</code> or <code>\tests\load\locustfiles\average_load.py</code></li>
<li>\tests\load\setup_k8s.sh</li>
</ul>
</li>
<li>Using Git, commit the changes locally</li>
</ul>
<h4 id="2-start-load-test"><a class="header" href="#2-start-load-test">2. Start Load Test</a></h4>
<ul>
<li>In a browser navigate to <code>http://$EXTERNAL_IP:8089</code>
This url can be generated via command
<pre><code class="language-bash">EXTERNAL_IP=$(kubectl get svc locust-master -o jsonpath=&quot;{.status.loadBalancer.ingress[0].ip}&quot;)
echo http://$EXTERNAL_IP:8089
</code></pre>
</li>
<li>Set up the load test parameters:
<ul>
<li>ShapeClass: SHAPE_CLASS</li>
<li>Host: 'https://stagepy.merino.nonprod.cloudops.mozgcp.net'</li>
</ul>
</li>
<li>Select &quot;Start Swarm&quot;</li>
</ul>
<h4 id="3-stop-load-test"><a class="header" href="#3-stop-load-test">3. Stop Load Test</a></h4>
<p>Select the 'Stop' button in the top right hand corner of the Locust UI, after the
desired test duration has elapsed. If the 'Run time', 'Duration' or 'ShapeClass'
are set in step 1, the load test will stop automatically.</p>
<h4 id="4-analyse-results"><a class="header" href="#4-analyse-results">4. Analyse Results</a></h4>
<p><strong>Stage Environment Pod Counts</strong></p>
<ul>
<li>The 'Merino-py Pod Count' should demonstrate scaling during the execution of the load test
<ul>
<li>The pod counts can be observed in <a href="https://earthangel-b40313e5.influxcloud.net/d/rQAfYKIVk/merino-py-application-and-infrastructure?orgId=1&amp;refresh=1m&amp;var-environment=stagepy">Grafana</a></li>
</ul>
</li>
</ul>
<p><strong>CPU and Memory Resources</strong></p>
<ul>
<li>CPU and Memory usage should be less than 90% of the available capacity in the cluster
<ul>
<li>CPU and Memory Resources can be observed in
<a href="https://console.cloud.google.com/kubernetes/list/overview?cloudshell=false&amp;project=spheric-keel-331521">Google Cloud &gt; Kubernetes Engine &gt; Workloads</a></li>
</ul>
</li>
</ul>
<h4 id="5-report-results"><a class="header" href="#5-report-results">5. Report Results</a></h4>
<ul>
<li>See <a href="testing/load-tests.html#4-report-results">Distributed GCP Execution (Manual Trigger) - Report Results</a></li>
</ul>
<h3 id="clean-up-environment-3"><a class="header" href="#clean-up-environment-3">Clean-up Environment</a></h3>
<ul>
<li>See <a href="testing/load-tests.html#clean-up-environment-1">Distributed GCP Execution (Manual Trigger) - Clean-up Environment</a></li>
</ul>
<h2 id="maintenance"><a class="header" href="#maintenance">Maintenance</a></h2>
<p>The load test maintenance schedule cadence is once a quarter and should include
updating the following:</p>
<ol>
<li><a href="https://python-poetry.org/docs/">poetry</a> version and python dependencies
<ul>
<li><input disabled="" type="checkbox"/>
<a href="https://github.com/mozilla-services/merino-py/blob/main/tests/load/pyproject.toml">pyproject.toml</a></li>
<li><input disabled="" type="checkbox"/>
<a href="https://github.com/mozilla-services/merino-py/blob/main/tests/load/poetry.lock">poetry.lock</a></li>
</ul>
</li>
<li><a href="https://docs.docker.com/">Docker</a> artifacts
<ul>
<li><input disabled="" type="checkbox"/>
<a href="https://github.com/mozilla-services/merino-py/blob/main/tests/load/Dockerfile">Dockerfile</a></li>
<li><input disabled="" type="checkbox"/>
<a href="https://github.com/mozilla-services/merino-py/blob/main/tests/load/docker-compose.yml">docker-compose.yml</a></li>
</ul>
</li>
<li>Distributed GCP execution scripts and Kubernetes configurations
<ul>
<li><input disabled="" type="checkbox"/>
<a href="https://github.com/mozilla-services/merino-py/blob/main/tests/load/setup_k8s.sh">setup_k8s.sh</a></li>
<li><input disabled="" type="checkbox"/>
<a href="https://github.com/mozilla-services/merino-py/blob/main/tests/load/kubernetes-config/locust-master-controller.yml">locust-master-controller.yml</a></li>
<li><input disabled="" type="checkbox"/>
<a href="https://github.com/mozilla-services/merino-py/blob/main/tests/load/kubernetes-config/locust-master-service.yml">locust-master-service.yml</a></li>
<li><input disabled="" type="checkbox"/>
<a href="https://github.com/mozilla-services/merino-py/blob/main/tests/load/kubernetes-config/locust-worker-controller.yml">locust-worker-controller.yml</a></li>
</ul>
</li>
<li>Documentation
<ul>
<li><input disabled="" type="checkbox"/>
<a href="testing/./load-tests.html">load test docs</a></li>
</ul>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="operations"><a class="header" href="#operations">Operations</a></h1>
<p>This is where we put operational documentation for Merino.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="how-to-rollback-changes"><a class="header" href="#how-to-rollback-changes">How to Rollback Changes</a></h1>
<p>Note: We use &quot;roll-forward&quot; strategy for rolling back changes in production.</p>
<ol>
<li>Depending on the severity of the problem, decide if this warrants
<a href="https://mozilla-hub.atlassian.net/wiki/spaces/MIR/overview">kicking off an incident</a>;</li>
<li>Identify the problematic commit (it may not be the latest commit)
and create a revert PR.
If it is the latest commit, you can revert the change with:
<pre><code>git revert HEAD~1
</code></pre>
</li>
<li>Create a revert PR and go through normal review process to merge PR.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="navigational-suggestions-job-blocklist"><a class="header" href="#navigational-suggestions-job-blocklist">Navigational Suggestions Job Blocklist</a></h1>
<p>The Navigational Suggestions Job blocklist is contained in <code>merino/utils/blocklists.py</code>.
The <code>TOP_PICKS_BLOCKLIST</code> variable is used when running the indexing job and prevents the included domains from being added.</p>
<h2 id="add-to-blocklist"><a class="header" href="#add-to-blocklist">Add to Blocklist</a></h2>
<ol>
<li>Go to <a href="https://github.com/mozilla-services/merino-py/blob/main/merino/utils/blocklists.py"><code>merino/utils/blocklists.py</code></a>.</li>
<li>Add the second-level-domain to the <code>TOP_PICKS_BLOCKLIST</code> set.</li>
<li>Open a PR and merge in the changes to block this domain from being indexed.</li>
</ol>
<h2 id="remove-from-blocklist"><a class="header" href="#remove-from-blocklist">Remove from Blocklist</a></h2>
<p>Repeat as above, just remove the domain from the <code>TOP_PICKS_BLOCKLIST</code> set.</p>
<ul>
<li>Note: removing from the blocklist means that the domain was likely not created during the Airflow job,
so if you wish to see it re-added, supposing it is still in the top 1000 domains, you have to re-run the airflow job.
See the instructions for this in the <a href="operations/./jobs/navigational_suggestions.html">jobs/navigational_suggestions docs</a>.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="how-to-add-to-the-wikipedia-indexer-and-provider-blocklist"><a class="header" href="#how-to-add-to-the-wikipedia-indexer-and-provider-blocklist">How to Add to the Wikipedia Indexer and Provider Blocklist</a></h1>
<h2 id="provider---rapid-blocklist-addition"><a class="header" href="#provider---rapid-blocklist-addition">Provider - Rapid Blocklist Addition</a></h2>
<p>These steps define how to rapidly add and therefore block a Wikipedia article by its title.</p>
<ol>
<li>In <code>/merino/utils/blocklists.py</code>, add the matching title to <code>TITLE_BLOCK_LIST</code>.</li>
</ol>
<p><em>NOTE:</em> Ensure the title field is added as it appears with correct spacing between the words.
In adding to the list, enter the title as it appears in Wikipedia.
Membership checks of the block list are not case sensitive and any underscores in the titles should instead be spaces.</p>
<ol start="2">
<li>Check in the changes to source control, merge a pull request with the new block list and deploy Merino.</li>
</ol>
<h2 id="indexer-job"><a class="header" href="#indexer-job">Indexer Job</a></h2>
<p>Since the indexer runs at a regular cadence, you do not need to re-run the Airflow job.
Adding to the blocklist using the steps above is sufficient to rapidly block a title.
The next time the Wikipedia indexer job runs, this title will be excluded during the indexer job.</p>
<p><em>NOTE:</em> There are two blocklists referenced by the Wikipedia Indexer Job:</p>
<ol>
<li><code>blocklist_file_url</code>: a key contained in the <code>merino/configs/default.toml</code> file that points to a remote block list which encapsulates blocked categories.</li>
<li><code>WIKIPEDIA_TITLE_BLOCKLIST</code>: an application-level list of titles found at <code>/merino/utils/blocklists.py</code> as explained above.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="what-to-do-with-test-failures-in-ci"><a class="header" href="#what-to-do-with-test-failures-in-ci">What to do with test failures in CI?</a></h1>
<ol>
<li>
<p>Investigate the cause of the test failure</p>
<ul>
<li>For unit or integration, logs can be found on <a href="https://app.circleci.com/pipelines/github/mozilla-services/merino-py">CircleCI</a></li>
<li>For performance tests (load), insights can be found on <a href="https://earthangel-b40313e5.influxcloud.net/d/rQAfYKIVk/wip-merino-py-application-and-infrastructure?orgId=1&amp;from=now-24h&amp;to=now&amp;var-environment=prodpy&amp;refresh=1m">Grafana</a> and in the
Locust logs. To access the Locust logs see the <a href="https://mozilla-services.github.io/merino-py/testing/load-tests.html">Distributed GCP Exection - CI Trigger</a>
section of the load test documentation.</li>
</ul>
</li>
<li>
<p>Fix or mitigate the failure</p>
<ul>
<li>If a fix can be identified in a relatively short time, then submit a fix</li>
<li>If the failure is caused by a flaky or intermittent functional test and the risk to the
end-user experience is low, then the test can be &quot;skipped&quot;, using the pytest<code>xfail</code>
<a href="https://docs.pytest.org/en/latest/how-to/skipping.html">decorator</a> during continued investigation. Example:
<pre><code class="language-python">@pytest.mark.xfail(reason=&quot;Test Flake Detected (ref: DISCO-####)&quot;)
</code></pre>
</li>
</ul>
</li>
<li>
<p>Re-Deploy</p>
<ul>
<li>A fix or mitigation will most likely require a PR merge to the <code>main</code> branch that will
automatically trigger the deployment process. If this is not possible, a re-deployment can be
initiated manually by triggering the CI pipeline in <a href="https://app.circleci.com/pipelines/github/mozilla-services/merino-py">CircleCI</a>.</li>
</ul>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="configuring-merino-operations"><a class="header" href="#configuring-merino-operations">Configuring Merino (Operations)</a></h1>
<p>To manage configurations and view all documentation for individual config values,
please view the <a href="https://github.com/mozilla-services/merino-py/tree/main/merino/configs/default.toml">default.toml</a> file.</p>
<h2 id="settings"><a class="header" href="#settings">Settings</a></h2>
<p>Merino's settings are managed via <a href="https://www.dynaconf.com/">Dynaconf</a> and can be specified in two ways:</p>
<ol>
<li>a <a href="https://toml.io/en/">TOML file</a> in the <code>merino/configs/</code> <a href="https://github.com/mozilla-services/merino-py/tree/main/merino/configs">directory</a>.</li>
<li>via environment variables.
Environment variables take precedence over the values set in the TOML files.
Production environment variables are managed by SRE and defined in the relevant merino-py repo.
TOML files set with the same environment name that is currently activated also automatically override defaults.
Any config file that is pointed to will override the <code>merino/configs/default.toml</code> file.</li>
</ol>
<h2 id="file-organization"><a class="header" href="#file-organization">File organization</a></h2>
<p>These are the settings sources, with later sources overriding earlier ones.</p>
<ul>
<li>
<p>A <a href="https://github.com/mozilla-services/merino-py/blob/main/merino/config.py"><code>config.py</code></a> file establishes a Dynaconf instance and environment-specific values
are pulled in from the corresponding TOML files and environment variables.
Other configurations are established by files that are prefixed with <code>config_*.py</code>,
such as <code>config_sentry.py</code> or <code>config_logging.py</code>.</p>
</li>
<li>
<p>Per-environment configuration files are in the <a href="https://github.com/mozilla-services/merino-py/tree/main/merino/configs"><code>configs</code> directory</a>.
The environment is selected using the environment variable <code>MERINO_ENV</code>.
The settings for that environment are then loaded from <code>configs/${env}.toml</code>, if the file/env exists. The default environment is &quot;development&quot;. A &quot;production&quot; environment is also provided.</p>
</li>
<li>
<p>Local configuration files are not checked into the repository,
but if created should be named <code>configs/development.local.toml</code>,
following the format of <code>&lt;environment&gt;.local.toml</code>.
This file is listed in the <code>.gitignore</code> file and is safe to use for local configuration.
One may add secrets here if desired, though it is advised to exercise great caution.</p>
</li>
</ul>
<h2 id="general"><a class="header" href="#general">General</a></h2>
<ul>
<li>
<p>All environments are prefixed with <code>MERINO_</code>.
This is established in the <code>config.py</code> file by setting the <code>envvar_prefix=&quot;MERINO&quot;</code>
for the Dynaconf instance.
The first level following <code>MERINO_</code> is accessed with a single underscore <code>_</code> and any subsequent levels require two underscores <code>__</code>.
For example, the logging format can be controlled from the environment variable <code>MERINO_LOGGING__FORMAT</code>.</p>
</li>
<li>
<p>Production environment variables are set by SRE and stored in the
cloudops project in the <code>configmap.yml</code> file.
Contact SRE if you require information or access on this file,
or request access to the cloudops infra repo.</p>
</li>
<li>
<p>You can set these environment variables in your setup by modifying the <code>.toml</code> files.
Conversely, when using <code>make</code>, you can prefix <code>make run</code> with overrides to the
desired environment variables using CLI flags.</p>
<p>Example:
<code>MERINO_ENV=production MERINO_LOGGING__FORMAT=pretty make dev</code></p>
</li>
<li>
<p><code>env</code> (<code>MERINO_ENV</code>) - Only settable from environment variables.
Controls which environment configuration is loaded, as described above.</p>
</li>
<li>
<p><code>debug</code> (<code>MERINO_DEBUG</code>) - Boolean that enables additional features to debug
the application.
This should not be set to true in public environments, as it reveals all configuration,
including any configured secrets.</p>
</li>
<li>
<p><code>format</code> (<code>MERINO_LOGGING__FORMAT</code>) - Controls the format of outputted logs in
either <code>pretty</code> or <code>mozlog</code> format. See <a href="https://github.com/mozilla-services/merino-py/blob/main/merino/configs/app_configs/config_logging.py">config_logging.py</a>.</p>
</li>
</ul>
<h2 id="caveat-1"><a class="header" href="#caveat-1">Caveat</a></h2>
<p>Be extra careful whenever you need to reference those deeply nested settings
(e.g. <code>settings.foo.bar.baz</code>) in the hot paths of the code base, such as middlewares
or route handlers. Under the hood, Dynaconf will perform a dictionary lookup
for each level of the configuration hierarchy. While it's harmless to do those
lookups once or twice, it comes a surprisingly high overhead if accessing them
repeatedly in the hot paths. You can cache those settings somewhere to mitigate
this issue.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="elasticsearch-operations"><a class="header" href="#elasticsearch-operations">Elasticsearch Operations</a></h1>
<p>We use Elasticsearch as a source of data for one of our providers.
This page documents some of the commands that we want to run on the cluster.</p>
<h2 id="elasticsearch-index-policy"><a class="header" href="#elasticsearch-index-policy">Elasticsearch Index Policy</a></h2>
<p>We want to ensure that the index expire after 30 days,
so we need to add a lifecycle policy for this deletion to happen.</p>
<p>The command to run in Kibana to add this policy:</p>
<pre><code>PUT _ilm/policy/enwiki_policy
{
  &quot;policy&quot;: {
    &quot;phases&quot;: {
      &quot;delete&quot;: {
        &quot;min_age&quot;: &quot;30d&quot;,
        &quot;actions&quot;: {
          &quot;delete&quot;: {}
        }
      }
    }
  }
}
</code></pre>
<h2 id="closed-index-recovery"><a class="header" href="#closed-index-recovery">Closed Index Recovery</a></h2>
<p>The indexing job currently <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-close.html">closes the index</a>
after it migrates the alias to point to the new index.
Closing the index removes the ability to query from the index
but also reduces the heap memory usage when the index is not actively being queried.</p>
<p>If there is a situation where we need to recover a closed index to be the main index,
we will need to do the following:</p>
<ol>
<li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-open-close.html">Re-open the index</a></li>
<li>Point the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-aliases.html">index alias</a> to the recovered index</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="jobs"><a class="header" href="#jobs">Jobs</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="merino-jobs-operations"><a class="header" href="#merino-jobs-operations">Merino Jobs Operations</a></h1>
<h2 id="navigational-suggestions"><a class="header" href="#navigational-suggestions">Navigational Suggestions</a></h2>
<p>This document provides instructions and documentation on the navigational suggestions job.
This job creates a file that is ingested by the Top Picks/Navigational Suggestions provider.
The provider indexes a collection of the top 1000 searched domains and generates the <code>top_picks.json</code> file.  Then the provider backend can serve suggestions that match query terms that are searched by the client to second-level domains.</p>
<p>If you need to run the navigational suggestions job ad-hoc, the quickest recommended solution is to run it in Airflow, download the <code>top_picks.json</code> file sent by email,
and then merge the new file into the Merino repo with the newly generated one.</p>
<p>If needing to update the blocklist to avoid certain domains and suggestions from being displayed,
please see the <a href="https://github.com/mozilla-services/merino-py/blob/main/docs/operations/blocklist-nav-suggestions.md">navigational suggestions blocklist runbook</a>.</p>
<h2 id="running-the-job-in-airflow"><a class="header" href="#running-the-job-in-airflow">Running the job in Airflow</a></h2>
<p>Normally, the job is set as a cron to run at set intervals as a <a href="https://airflow.apache.org/docs/apache-airflow/stable/public-airflow-interface.html#dags">DAG in Airflow</a>.
There may be instances you need to manually re-run the job from the Airflow dashboard.</p>
<h3 id="grid-view-tab-airflow-ui"><a class="header" href="#grid-view-tab-airflow-ui">Grid View Tab (Airflow UI)</a></h3>
<ol>
<li>Visit the <a href="https://workflow.telemetry.mozilla.org/dags/merino_jobs/grid">Airflow dashboard for <code>merino_jobs</code></a>.</li>
<li>In the Grid View Tab, select the task you want to re-run.</li>
<li>Click on 'Clear Task' and the executor will re-run the job.
<img src="operations/jobs/dag_ui.png" alt="merino_jobs UI Diagram" title="merino_jobs UI Diagram" /></li>
</ol>
<h3 id="graph-view-tab-airflow-ui---alternative"><a class="header" href="#graph-view-tab-airflow-ui---alternative">Graph View Tab (Airflow UI) - Alternative</a></h3>
<ol>
<li>Visit the <a href="https://workflow.telemetry.mozilla.org/dags/merino_jobs/graph?root=">Airflow dashboard for <code>merino_jobs</code></a>.</li>
<li>From the Graph View Tab, Click on the <code>nav_suggestions_prepare_domain_metadata_prod</code> task.
<img src="operations/jobs/nav_sug_graph_view.png" alt="merino_jobs Nav Suggest Graph View" title="merino_jobs UI Graph View" /></li>
<li>Click on 'Clear' and the job will re-run.
<img src="operations/jobs/nav_task_instance_clear.png" alt="merino_jobs UI Task Instance Clear" title="merino_jobs UI Task Clear" /></li>
</ol>
<p>At the conclusion of the job, you should recieve an email with a link to the newly generated file. Ensure you are a member of the <code>disco-team</code> email distro group to recieve the email.</p>
<p>Note: You can also re-run the stage job, but the changes won't reflect in production. Stage should be re-run in the event of an error before running in prod to verify the correction of an error.</p>
<p>See Airflow's <a href="https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/dag-run.html#re-run-dag">documentation on re-running DAGs</a> for more information and implementation details.</p>
<p>To see the code for the <code>merino_jobs</code> DAG, visit the <a href="https://github.com/mozilla/telemetry-airflow/blob/main/dags/merino_jobs.py">telemetry-airflow repo</a>. The source for the job is also in the <a href="https://workflow.telemetry.mozilla.org/dags/merino_jobs/code?root=">'code' tab</a> in the airflow console.</p>
<p>To see the navigational suggestions code that is run when the job is invoked, visit <a href="https://github.com/mozilla-services/merino-py/tree/main/merino/jobs/navigational_suggestions">Merino <code>jobs/navigational_suggestions</code></a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="merino-jobs-operations-1"><a class="header" href="#merino-jobs-operations-1">Merino Jobs Operations</a></h1>
<h2 id="dynamic-wikipedia-indexer-job"><a class="header" href="#dynamic-wikipedia-indexer-job">Dynamic Wikipedia Indexer Job</a></h2>
<p>Merino currently builds the Elasticsearch indexing job that runs in Airflow.
Airflow takes the <code>latest</code> image built as the base image.
The reasons to keep the job code close to the application code are:</p>
<ol>
<li>Data models can be shared between the indexing job and application more easily.
This means that data migrations will be simpler.</li>
<li>All the logic regarding Merino functionality can be found in one place.</li>
<li>Eliminates unintended differences in functionality due to dependency mismatch.</li>
</ol>
<p>If your reason for re-running the job is needing to update the blocklist to avoid certain suggestions from being displayed,
please see the <a href="https://github.com/mozilla-services/merino-py/blob/main/docs/operations/blocklist-wikipedia.md">wikipedia blocklist runbook</a>.</p>
<h2 id="running-the-job-in-airflow-1"><a class="header" href="#running-the-job-in-airflow-1">Running the job in Airflow</a></h2>
<p>Normally, the job is set as a cron to run at set intervals as a <a href="https://airflow.apache.org/docs/apache-airflow/stable/public-airflow-interface.html#dags">DAG in Airflow</a>.
There may be instances you need to manually re-run the job from the Airflow dashboard.</p>
<h3 id="grid-view-tab-airflow-ui-1"><a class="header" href="#grid-view-tab-airflow-ui-1">Grid View Tab (Airflow UI)</a></h3>
<ol>
<li>Visit the <a href="https://workflow.telemetry.mozilla.org/dags/merino_jobs/grid">Airflow dashboard for <code>merino_jobs</code></a>.</li>
<li>In the Grid View Tab, select the task you want to re-run.</li>
<li>Click on 'Clear Task' and the executor will re-run the job.
<img src="operations/jobs/dag_ui_wiki.png" alt="merino_jobs UI Diagram" title="merino_jobs UI Diagram" /></li>
</ol>
<h3 id="graph-view-tab-airflow-ui---alternative-1"><a class="header" href="#graph-view-tab-airflow-ui---alternative-1">Graph View Tab (Airflow UI) - Alternative</a></h3>
<ol>
<li>Visit the <a href="https://workflow.telemetry.mozilla.org/dags/merino_jobs/graph?root=">Airflow dashboard for <code>merino_jobs</code></a>.</li>
<li>From the Graph View Tab, Click on the <code>wikipedia_indexer_build_index_production</code> task.
<img src="operations/jobs/wiki_graph_view.png" alt="merino_jobs Wikipedia Indexer Graph View" title="merino_jobs UI Graph View" /></li>
<li>Click on 'Clear' and the job will re-run.
<img src="operations/jobs/wiki_task_instance_clear.png" alt="merino_jobs UI Task Instance Clear" title="merino_jobs UI Task Clear" /></li>
</ol>
<p>Note: You can also re-run the stage job, but the changes won't reflect in production. Stage should be re-run in the event of an error before running in prod to verify the correction of an error.</p>
<p>See Airflow's <a href="https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/dag-run.html#re-run-dag">documentation on re-running DAGs</a> for more information and implementation details.</p>
<p>To see the code for the <code>merino_jobs</code> DAG, visit the <a href="https://github.com/mozilla/telemetry-airflow/blob/main/dags/merino_jobs.py">telemetry-airflow repo</a>. The source for the job is also in the <a href="https://workflow.telemetry.mozilla.org/dags/merino_jobs/code?root=">'code' tab</a> in the airflow console.</p>
<p>To see the Wikipedia Indexer code that is run when the job is invoked, visit <a href="https://github.com/mozilla-services/merino-py/tree/main/merino/jobs/wikipedia_indexer">Merino <code>jobs/wikipedia_indexer</code></a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="merino-jobs-operations-2"><a class="header" href="#merino-jobs-operations-2">Merino Jobs Operations</a></h1>
<h2 id="csv-remote-settings-uploader-job"><a class="header" href="#csv-remote-settings-uploader-job">CSV Remote Settings Uploader Job</a></h2>
<p>The CSV remote settings uploader is a job that uploads suggestions data in a CSV
file to remote settings. It takes two inputs:</p>
<ol>
<li>A CSV file. The first row in the file is assumed to be a header that names
the fields (columns) in the data.</li>
<li>A Python module that validates the CSV contents and describes how to convert
it into suggestions JSON.</li>
</ol>
<p>If you're uploading suggestions from a Google sheet, you can export a CSV file
from File &gt; Download &gt; Comma Separated Values (.csv). Make sure the first row in
the sheet is a header that names the columns.</p>
<h3 id="uploading-suggestions-step-by-step"><a class="header" href="#uploading-suggestions-step-by-step">Uploading suggestions (Step by step)</a></h3>
<p>If you're uploading a type of suggestion that the uploader already supports,
skip to <a href="operations/jobs/csv-remote-settings.html#running-the-uploader">Running the uploader</a> below. If you're not sure
whether it's supported, check in the <code>merino/jobs/csv_rs_uploader/</code> directory
for a file named similarly to the type.</p>
<p>To upload a new type of suggestion, follow the steps below. In summary, first
you'll create a Python module that implements a model for the suggestion type,
and then you'll run the uploader.</p>
<h4 id="1-create-a-python-model-module-for-the-new-suggestion-type"><a class="header" href="#1-create-a-python-model-module-for-the-new-suggestion-type">1. Create a Python model module for the new suggestion type</a></h4>
<p>Add a Python module to <code>merino/jobs/csv_rs_uploader/</code>. It's probably easiest to
copy an existing model module like <code>mdn.py</code>, follow along with the steps here,
and modify it for the new suggestion type. Name the file according to the
suggestion type.</p>
<p>This file will define the model of the new suggestion type as it will be
serialized in the output JSON, perform validation and conversion of the input
data in the CSV, and define how the input data should map to the output JSON.</p>
<h4 id="2-add-the-suggestion-class"><a class="header" href="#2-add-the-suggestion-class">2. Add the <code>Suggestion</code> class</a></h4>
<p>In the module, implement a class called <code>Suggestion</code> that derives from
<code>BaseSuggestion</code> in <code>merino.jobs.csv_rs_uploader.base</code> or
<code>RowMajorBaseSuggestion</code> in <code>merino.jobs.csv_rs_uploader.row_major_base</code>.
<code>BaseSuggestion</code> class will be the model of the new suggestion type.
<code>BaseSuggestion</code> itself derives from Pydantic's <code>BaseModel</code>, so the validation
the class will perform will be based on <a href="https://docs.pydantic.dev/latest/usage/models/">Pydantic</a>, which is used
throughout Merino. <code>BaseSuggestion</code> is implemented in <code>base.py</code>. If the CSV data
is row-major based, please use <code>RowMajorBaseSuggestion</code>,</p>
<h4 id="3-add-suggestion-fields-to-the-class"><a class="header" href="#3-add-suggestion-fields-to-the-class">3. Add suggestion fields to the class</a></h4>
<p>Add a field to the class for each property that should appear in the output JSON
(except <code>score</code>, which the uploader will add automatically). Name each field as
you would like it to be named in the JSON. Give each field a type so that
Pydantic can validate it. For URL fields, use <code>HttpUrl</code> from the <code>pydantic</code>
module.</p>
<h4 id="4-add-validator-methods-to-the-class"><a class="header" href="#4-add-validator-methods-to-the-class">4. Add validator methods to the class</a></h4>
<p>Add a method annotated with Pydanyic's <code>@field_validator</code> decorator for each field.
Each validator method should transform its field's input value into an appropriate output value and raise a <code>ValueError</code> if the input value is invalid.
Pydantic will call these methods automatically as it performs validation.
Their return values will be used as the values in the output JSON.</p>
<p><code>BaseSuggestion</code> implements two helpers you should use:</p>
<ul>
<li><code>_validate_str()</code> - Validates a string value and returns the validated value.
Leading and trailing whitespace is stripped, and all whitespace is replaced
with spaces and collapsed. Returns the validated value.</li>
<li><code>_validate_keywords()</code> - The uploader assumes that lists of keywords are
serialized in the input data as comma-delimited strings. This helper method
takes a comma-delimited string and splits it into individual keyword strings.
Each keyword is converted to lowercase, some non-ASCII characters are replaced
with ASCII equivalents that users are more likely to type, leading and
trailing whitespace is stripped, all whitespace is replaced with spaces and
collapsed, and duplicate keywords are removed. Returns the list of keyword
strings.</li>
</ul>
<h4 id="5-implement-the-class-methods"><a class="header" href="#5-implement-the-class-methods">5. Implement the class methods</a></h4>
<p>For suggestion created from row-major based CSV, should add a <code>@classmethod</code> to
<code>Suggestion</code> called <code>row_major_field_map()</code>. It should return a <code>dict</code> that maps
from field (column) names in the input CSV to property names in the output JSON.
Otherwise, should add a <code>@classmethod</code> to <code>Suggestion</code> called
<code>csv_to_suggestions()</code>. It should return suggestion array created from passed CSV
reader.</p>
<h4 id="6-add-a-test"><a class="header" href="#6-add-a-test">6. Add a test</a></h4>
<p>Add a test file to <code>tests/unit/jobs/csv_rs_uploader/</code>. See <code>test_mdn.py</code> as an
example. The test should perform a successful upload as well as uploads that
fail due to validation errors and missing fields (columns) in the input CSV.</p>
<p><code>utils.py</code> in the same directory implements helpers that your test should use:</p>
<ul>
<li><code>do_csv_test()</code> - Makes sure the uploader works correctly during a successful
upload. It takes either a path to a CSV file or a <code>list[dict]</code> that will be
used to create a file object (<code>StringIO</code>) for an in-memory CSV file. Prefer
passing in a <code>list[dict]</code> instead of creating a file and passing a path, since
it's simpler.</li>
<li><code>do_error_test()</code> - Makes sure a given error is raised when expected. Use
<code>ValidationError</code> from the <code>pydantic</code> module to check validation errors and
<code>MissingFieldError</code> from <code>merino.jobs.csv_rs_uploader</code> to check input CSV that
is missing an expected field (column).</li>
</ul>
<h4 id="7-run-the-test"><a class="header" href="#7-run-the-test">7. Run the test</a></h4>
<pre><code>$ MERINO_ENV=testing poetry run pytest tests/unit/jobs/csv_rs_uploader/test_foo.py
</code></pre>
<p>See also the main Merino development documentation for running unit tests.</p>
<h4 id="8-submit-a-pr"><a class="header" href="#8-submit-a-pr">8. Submit a PR</a></h4>
<p>Once your test is passing, submit a PR with your changes so that the new
suggestion type is committed to the repo. This step isn't necessary to run the
uploader and upload your suggestions, so you can come back to it later.</p>
<h4 id="9-upload"><a class="header" href="#9-upload">9. Upload!</a></h4>
<p>See <a href="operations/jobs/csv-remote-settings.html#running-the-uploader">Running the uploader</a>.</p>
<h3 id="running-the-uploader"><a class="header" href="#running-the-uploader">Running the uploader</a></h3>
<p>Run the following from the repo's root directory to see documentation for all
options and their defaults. Note that the <code>upload</code> command is the only command
in the <code>csv-rs-uploader</code> job.</p>
<pre><code>poetry run merino-jobs csv-rs-uploader upload --help`
</code></pre>
<p>The uploader takes a CSV file as input, so you'll need to download or create one
first.</p>
<p>Here's an example that uploads suggestions in <code>foo.csv</code> to the remote settings
dev server:</p>
<pre><code>poetry run merino-jobs csv-rs-uploader upload \
  --server &quot;https://remote-settings-dev.allizom.org/v1&quot; \
  --bucket main-workspace \
  --csv-path foo.csv \
  --model-name foo \
  --record-type foo-suggestions \
  --auth &quot;Bearer ...&quot;
</code></pre>
<p>Let's break down each command-line option in this example:</p>
<ul>
<li><code>--server</code> - Suggestions will be uploaded to the remote settings dev server</li>
<li><code>--bucket</code> - The <code>main-workspace</code> bucket will be used</li>
<li><code>--csv-path</code> - The CSV input file is <code>foo.csv</code></li>
<li><code>--model-name</code> - The model module is named <code>foo</code>. Its path within the repo
would be <code>merino/jobs/csv_rs_uploader/foo.py</code></li>
<li><code>--record-type</code> - The <code>type</code> in the remote settings records created for these
suggestions will be set to <code>foo-suggestions</code>. This argument is optional and
defaults to <code>&quot;{model_name}-suggestions&quot;</code></li>
<li><code>--auth</code> - Your authentication header string from the server. To get a header,
log in to the server dashboard (don't forget to log in to the Mozilla VPN
first) and click the small clipboard icon near the top-right of the page,
after the text that shows your username and server URL. The page will show a
&quot;Header copied to clipboard&quot; toast notification if successful.</li>
</ul>
<h4 id="setting-suggestion-scores"><a class="header" href="#setting-suggestion-scores">Setting suggestion scores</a></h4>
<p>By default all uploaded suggestions will have a <code>score</code> property whose value is
defined in the <code>remote_settings</code> section of the Merino config. This default can
be overridden using <code>--score &lt;number&gt;</code>. The number should be a float between 0
and 1 inclusive.</p>
<h4 id="other-useful-options"><a class="header" href="#other-useful-options">Other useful options</a></h4>
<ul>
<li><code>--dry-run</code> - Log the output suggestions but don't upload them. The uploader
will still authenticate with the server, so <code>--auth</code> must still be given.</li>
</ul>
<h3 id="structure-of-the-remote-settings-data"><a class="header" href="#structure-of-the-remote-settings-data">Structure of the remote settings data</a></h3>
<p>The uploader uses <code>merino/jobs/utils/chunked_rs_uploader.py</code> to upload the
output suggestions. In short, suggestions will be chunked, and each chunk will
have a corresponding remote settings record with an attachment. The record's ID
will be generated from the <code>--record-type</code> option, and its type will be set to
<code>--record-type</code> exactly. The attachment will contain a JSON array of suggestion
objects in the chunk.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="merino-adrs"><a class="header" href="#merino-adrs">Merino ADRs</a></h1>
<p>This directory archives all the Architectural Decision Records (ADRs) for Merino.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="locust-vs-k6-merino-py-performance-test-framework"><a class="header" href="#locust-vs-k6-merino-py-performance-test-framework">Locust vs k6; Merino-py Performance Test Framework</a></h1>
<ul>
<li><strong>Status:</strong> Accepted</li>
<li><strong>Deciders:</strong> Nan Jiang, Raphael Pierzina &amp; Katrina Anderson</li>
<li><strong>Date:</strong> 2023-02-21</li>
</ul>
<h2 id="context-and-problem-statement"><a class="header" href="#context-and-problem-statement">Context and Problem Statement</a></h2>
<p>Performance testing for the Rust version of Merino was conducted with the <a href="https://locust.io/">Locust</a>
test framework and focused on the detection of HTTP request failures. During the
migration of Merino from Rust to Python, performance testing was conducted with <a href="https://k6.io/">k6</a>
and focused on the evaluation of request latency. Going forward a unified performance
testing solution is preferred, should the test framework be Locust or k6?</p>
<h2 id="decision-drivers"><a class="header" href="#decision-drivers">Decision Drivers</a></h2>
<ol>
<li>The test framework supports the current load test design, a 10-minute test run with
an average load of 1500RPS (see <a href="https://docs.google.com/document/d/1v7LDXENPZg37KXeNcznEZKNZ8rQlOhNbsHprFyMXHhs/edit?usp=sharing">Merino Load Test Plan</a>)</li>
<li>The test framework measures HTTP request failure and client-side latency metrics</li>
<li>The test framework is compatible with the Rapid Release Model for Firefox Services
initiative, meaning:
<ul>
<li>It can execute through command line</li>
<li>It can signal failures given check or threshold criteria</li>
<li>It can be integrated into a CD pipeline</li>
<li>It can report metrics to <a href="https://earthangel-b40313e5.influxcloud.net/?orgId=1%5D">Grafana</a></li>
</ul>
</li>
<li>The members of the DISCO and ETE teams are able to contribute to and maintain load
tests written with the test framework</li>
</ol>
<h2 id="considered-options"><a class="header" href="#considered-options">Considered Options</a></h2>
<ul>
<li>A. Locust</li>
<li>B. k6</li>
</ul>
<h2 id="decision-outcome"><a class="header" href="#decision-outcome">Decision Outcome</a></h2>
<p>Chosen option:</p>
<ul>
<li><strong>A. Locust</strong></li>
</ul>
<p>Both k6 and Locust are able to execute the current load test design, report required
metrics and fulfill the Rapid Release Model for Firefox Services initiative; However,
Locust's Python tech stack ultimately makes it the better fit for the Merino-py
project. In-line with the team's single repository direction (see <a href="https://github.com/mozilla-services/merino-py/pull/186">PR</a>), using
Locust will:</p>
<ul>
<li>Leverage existing testing, linting and formatting infrastructure</li>
<li>Promote dependency sharing and code re-use (models &amp; backends)</li>
</ul>
<h2 id="pros-and-cons-of-the-options"><a class="header" href="#pros-and-cons-of-the-options">Pros and Cons of the Options</a></h2>
<h3 id="a-locust"><a class="header" href="#a-locust">A. Locust</a></h3>
<p><a href="https://locust.io/">Locust</a> can be viewed as the status quo option, since it is the framework that is
currently integrated into the Merino-py repository and is the basis for the CD load
test integration currently underway (see <a href="https://mozilla-hub.atlassian.net/browse/DISCO-2113">DISCO-2113</a>).</p>
<h4 id="pros"><a class="header" href="#pros">Pros</a></h4>
<ul>
<li>Locust has a mature distributed load generation feature and can easily support a 1500
RPS load</li>
<li>Locust has built-in RPS, HTTP request failure and time metrics with customizable URL
break-down</li>
<li>Locust scripting is in Python</li>
<li>Locust supports direct command line usage</li>
<li>Locust is used for load testing in other Mozilla projects and is recommended by the
ETE team</li>
</ul>
<h4 id="cons"><a class="header" href="#cons">Cons</a></h4>
<ul>
<li>Locust is 100% community driven (no</li>
<li>commercial business), which means its
contribution level can wane</li>
<li>Preliminary research indicates that reporting metrics from Locust to <a href="https://earthangel-b40313e5.influxcloud.net/?orgId=1%5D">Grafana</a>
requires the creation of custom code, a plugin or a third party integration</li>
</ul>
<h3 id="b-k6"><a class="header" href="#b-k6">B. k6</a></h3>
<p>For the launch of Merino-py, performance bench-marking was conducted using a <a href="https://k6.io/">k6</a>
load test script (see <a href="https://github.com/quiiver/merino-explorations">Merino Explorations</a>). This script was reused from the Merino
rewrite exploration effort and has proven successful in assessing if Merino-py
performance achieves the target p95 latency threshold, effecting preventative change
(See <a href="https://github.com/mozilla-services/merino-py/pull/67#issuecomment-1266031853">PR</a>). k6's effectiveness and popularity amongst team members is an incentive
to pause and evaluate if it is a more suitable framework going forward.</p>
<h4 id="pros-1"><a class="header" href="#pros-1">Pros</a></h4>
<ul>
<li>k6 is an open-source commercially backed framework with a high contribution rate</li>
<li>k6 is built by Grafana Labs, inferring easy integration with dashboards</li>
<li>k6 has built-in RPS, HTTP request failure and time metrics with customizable URL
break-down</li>
<li>k6 supports direct command line usage</li>
<li>k6 is feature rich, including built-in functions to generate pass/fail results and
create custom metrics</li>
</ul>
<h4 id="cons-1"><a class="header" href="#cons-1">Cons</a></h4>
<ul>
<li>The k6 development stack is in JavaScript/TypeScript. This means:
<ul>
<li>Modeling and backend layer code would need to be duplicated and maintained</li>
<li>Linting, formatting and dependency infrastructure would need to be added and
maintained</li>
</ul>
</li>
<li>k6 has an immature distributed load generation feature, with <a href="https://k6.io/docs/testing-guides/running-large-tests/#distributed-execution">documented</a>
limitations
<ul>
<li>k6 runs more efficiently than other frameworks, so it may be possible to achieve
1500 RPS without distribution</li>
</ul>
</li>
</ul>
<h2 id="links"><a class="header" href="#links">Links</a></h2>
<ul>
<li><a href="https://mozilla-hub.atlassian.net/browse/DISCO-2045">DISCO-2045 - Investigate K6 load testing in Merino-py CD</a></li>
</ul>
<!-- References -->
<div style="break-before: page; page-break-before: always;"></div><h1 id="merino-suggest-api-response-structure"><a class="header" href="#merino-suggest-api-response-structure">Merino Suggest API Response Structure</a></h1>
<ul>
<li>Status: accepted</li>
<li>Deciders: Michelle Tran, Lina Butler, Nan Jiang, Wil Stuckey,
Drew Willcoxon, Taddes Korris, Tiffany Tran</li>
<li>Date: 2023-04-20</li>
</ul>
<h2 id="context-and-problem-statement-1"><a class="header" href="#context-and-problem-statement-1">Context and Problem Statement</a></h2>
<p>As Merino continues to add more suggestions,
suggestion providers are going to have to return all sorts of
data to the clients that are bespoke to the particular suggestion.
For instance, weather suggestion returns a <code>temperature</code>.
Currently, we do not have a strategy to manage these bespoke pieces of data
which results in them returned at the top level of the suggestion object.
However, this will pose a problem when</p>
<ol>
<li>names of fields are shared between providers, but have different semantics
(i.e. <code>rating</code> may be a decimal value between 0-1 in one type,
and a &quot;star&quot; integer rating between 1-5 in another)</li>
<li>the API is unclear about what will <em>necessarily</em> exist, and what is <em>optional</em>,
which leads to client confusion about the contract</li>
</ol>
<p>So, this ADR is to make a decision on how we want to handle provider specific fields
going forward.</p>
<h2 id="decision-drivers-1"><a class="header" href="#decision-drivers-1">Decision Drivers</a></h2>
<p>In rough order of importance:</p>
<ol>
<li>Explicitness of Ownership - i.e. the <code>rating</code> field belongs to the <code>addons</code> provider</li>
<li>Compatibility with [JSON] Schema Validation</li>
<li>Adherence to the Fx Suggest Design Framework</li>
<li>Backwards Compatibility with Current Schema</li>
</ol>
<h2 id="considered-options-1"><a class="header" href="#considered-options-1">Considered Options</a></h2>
<ul>
<li>A. Continue to add to Top Level with Optional Fields</li>
<li>B. Custom Details Field for Bespoke Provider Fields</li>
<li>B.5 Custom Details Field without the Provider Nesting</li>
<li>C. Custom Details Field for a &quot;Type&quot;</li>
<li>D. Component Driven <code>custom_details</code></li>
</ul>
<h2 id="decision-outcome-1"><a class="header" href="#decision-outcome-1">Decision Outcome</a></h2>
<p>Chosen option: B</p>
<p>We will also <em>not</em> increase the version number of the API for this ADR.
So, going forward, we will encode option B into the response design
without changing the existing providers.
This means that the following providers will <em>not</em> have
their bespoke fields removed from top level:</p>
<ul>
<li>AdM Provider</li>
<li>Top Picks Provider</li>
<li>Weather Provider</li>
<li>Wikipedia Provider</li>
<li>WikiFruit Provider</li>
</ul>
<p>However, this does not preclude these providers from duplicating the fields
to <code>custom_details</code> in the v1 API.</p>
<h3 id="positive-consequences-of-option-b"><a class="header" href="#positive-consequences-of-option-b">Positive Consequences of Option B</a></h3>
<ul>
<li>Clear isolation of fields that belong together (i.e. grouped by provider).</li>
<li>Clear ownership of fields through the structure.</li>
<li>Simpler validation logic than other options due to less need for conditionals.</li>
</ul>
<h3 id="negative-consequences-of-option-b"><a class="header" href="#negative-consequences-of-option-b">Negative Consequences of Option B</a></h3>
<ul>
<li>Potentially some redundancy caused by extra nesting.</li>
<li>Might not be as flexible with a provider that returns different fields based on
what type of suggestion it is.</li>
</ul>
<h3 id="positive-consequences-of-not-increasing-api-version"><a class="header" href="#positive-consequences-of-not-increasing-api-version">Positive Consequences of not Increasing API Version</a></h3>
<ul>
<li>We do not have to worry about migrating Firefox (and other clients) into the new format.
The migration is going to be quite a lot of extra work that adds little benefits
(other than consistency of design, it doesn't add more features nor improve
any known time sinks with development).</li>
<li>Do not have to support 2 versions of the API.</li>
</ul>
<h3 id="negative-consequences-of-not-increasing-api-version"><a class="header" href="#negative-consequences-of-not-increasing-api-version">Negative Consequences of not Increasing API Version</a></h3>
<ul>
<li>Some inconsistencies with how providers add fields to the response.
We will likely want to resolve this as we migrate to v2,
but it's a known issue at the moment.</li>
<li>Might be missing an opportune time to migrate, as features are currently not out yet
which means the flexibility for change is higher.</li>
</ul>
<h2 id="pros-and-cons-of-the-options-1"><a class="header" href="#pros-and-cons-of-the-options-1">Pros and Cons of the Options</a></h2>
<h3 id="a-continue-to-add-to-top-level-with-optional-fields"><a class="header" href="#a-continue-to-add-to-top-level-with-optional-fields">A. Continue to add to Top Level with Optional Fields</a></h3>
<p>This is the status quo option.
We will continue to append bespoke values to the top level suggestion,
and ensure that they're optional.
We can continue to use the <code>provider</code> to signal what fields exists
and how they should be parsed.
For example, we can specify 2 different types of <code>rating</code>,
and hence 2 validation strategy for it,
based off of which provider is specified.</p>
<p>Example:</p>
<pre><code class="language-json">{
  &quot;suggestions&quot;: [
    {
      ...
      &quot;provider&quot;: &quot;addons&quot;,
      &quot;rating&quot;: &quot;4.123&quot;,
      ...
    },
    {
      ...
      &quot;provider&quot;: &quot;movies&quot;,
      &quot;rating&quot;: 0.123,
      ...
    },
    ...
  ],
  ...
}
</code></pre>
<p>The partial JSON Schema validation will look something like:</p>
<pre><code class="language-json">{
  &quot;type&quot;: &quot;object&quot;,
  &quot;properties&quot;: {
    &quot;provider&quot;: {
      &quot;type&quot;: &quot;string&quot;
    }
  },
  &quot;required&quot;: [&quot;provider&quot;],
  &quot;allOf&quot;: [
    {
      &quot;if&quot;: {
        &quot;properties&quot;: {
          &quot;provider&quot;: {
            &quot;const&quot;: &quot;addons&quot;
          }
        }
      },
      &quot;then&quot;: {
        &quot;properties&quot;: {
          &quot;rating&quot;: {
            &quot;type&quot;: &quot;string&quot;
          }
        },
        &quot;required&quot;: [
          &quot;rating&quot;
        ]
      }
    },
    {
      &quot;if&quot;: {
        &quot;properties&quot;: {
          &quot;provider&quot;: {
            &quot;const&quot;: &quot;movies&quot;
          }
        }
      },
      &quot;then&quot;: {
        &quot;properties&quot;: {
          &quot;rating&quot;: {
            &quot;type&quot;: &quot;number&quot;
          }
        },
        &quot;required&quot;: [
          &quot;rating&quot;
        ]
      }
    }
  ]
}
</code></pre>
<h4 id="pros-2"><a class="header" href="#pros-2">Pros</a></h4>
<ul>
<li>Can specify specific validation per provider.</li>
<li>Merino is still kind of immature, so it still might be too early to think about design.</li>
<li>Less nesting in the models (resulting in less complexity).</li>
<li>Currently, backwards compatible as we don't have to do anything
to existing providers, as this follows the existing patterns.</li>
</ul>
<h4 id="cons-2"><a class="header" href="#cons-2">Cons</a></h4>
<ul>
<li>Lack of isolation for bespoke fields; <code>ratings</code> is coupled with 2 specific providers,
and by just looking at the response, it's not clear that they are related.</li>
<li>Not clear what is shared between <em>all</em> suggestions, vs. what is bespoke to specific provider.</li>
<li>It is not obvious that the <code>provider</code> field should signal how you should perform validation.
In other words, there is a contextual dependency on the JSON structure of suggestion based on <code>provider</code>.</li>
</ul>
<h3 id="b-custom-details-field-for-bespoke-provider-fields"><a class="header" href="#b-custom-details-field-for-bespoke-provider-fields">B. Custom Details Field for Bespoke Provider Fields</a></h3>
<p>We introduce a <code>custom_details</code> field that uses a provider name as key
to an object with the bespoke values to that provider.</p>
<p>Example:</p>
<pre><code class="language-json">{
  &quot;suggestions&quot;: [
    {
      ...
      &quot;provider&quot;: &quot;addons&quot;,
      &quot;custom_details&quot;: {
        &quot;addons&quot;: {
          &quot;rating&quot;: &quot;4.7459&quot;
        }
      }
    },
    ...
  ],
  ...
}
</code></pre>
<p>The specific fields in <code>custom_details</code> will all be optional (i.e. <code>addons</code> will be an optional key)
but the <em>shape</em> of what goes in <code>addons</code> can be more strict (i.e. <code>addons</code> require a <code>rating</code> field).</p>
<p>A partial schema specification for the above might look like<sup class="footnote-reference"><a href="#jsonschema">1</a></sup>:</p>
<pre><code class="language-json">{
  &quot;$schema&quot;: &quot;https://json-schema.org/draft/2020-12/schema&quot;,
  &quot;title&quot;: &quot;Suggest API Response v1&quot;,
  &quot;description&quot;: &quot;Response for /api/v1/suggest&quot;,
  &quot;type&quot;: &quot;object&quot;,
  &quot;properties&quot;: {
    &quot;provider&quot;: {
      &quot;description&quot;: &quot;id for the provider type&quot;,
      &quot;type&quot;: &quot;string&quot;
    },
    &quot;custom_details&quot;: {
      &quot;type&quot;: &quot;object&quot;,
      &quot;properties&quot;: {
        &quot;addons&quot;: {
          &quot;type&quot;: &quot;object&quot;,
          &quot;description&quot;: &quot;Custom Addon Fields&quot;,
          &quot;properties&quot;: {
            &quot;rating&quot;: {
              &quot;type&quot;: &quot;number&quot;
            }
          },
          &quot;required&quot;: [&quot;rating&quot;]
        }
      }
    }
  },
  &quot;required&quot;: [&quot;provider&quot;]
}
</code></pre>
<div class="footnote-definition" id="jsonschema"><sup class="footnote-definition-label">1</sup>
<p>Can play with JSON schema in https://www.jsonschemavalidator.net/</p>
</div>
<h4 id="pros-3"><a class="header" href="#pros-3">Pros</a></h4>
<ul>
<li>Can specify specific validation per provider.</li>
<li>Clear ownership of <code>rating</code> to <code>addons</code> via structure.</li>
<li>Fields outside of <code>custom_details</code> can be fields that are more universal across suggestions.
These fields can potentially be correlated directly to the Fx Suggest Design Framework
(i.e. <code>context_label</code>, <code>url</code>, <code>title</code>, <code>description</code>, etc.).</li>
<li>Having a clear distinction for Fx Suggest Design Framework fields vs. bespoke fields makes this more
backwards compatible, as the fields in the Design Framework can render the <em>default</em> suggestion case
for clients who haven't upgraded their clients.</li>
</ul>
<h4 id="cons-3"><a class="header" href="#cons-3">Cons</a></h4>
<ul>
<li>We'll likely need to migrate existing providers at some point. But in the meantime,
some fields will not follow convention to maintain backwards compatibility.</li>
<li>Extra nesting inside of <code>custom_details</code>.</li>
</ul>
<h3 id="b5-custom-details-field-without-the-provider-nesting"><a class="header" href="#b5-custom-details-field-without-the-provider-nesting">B.5 Custom Details Field without the Provider Nesting</a></h3>
<p>This is exactly like B, except that we remove the extra nesting.</p>
<p>So, in the example above, we can remove the extra <code>addons</code> object to get:</p>
<pre><code class="language-json">{
  &quot;suggestions&quot;: [
    {
      ...
      &quot;provider&quot;: &quot;addons&quot;,
      &quot;custom_details&quot;: {
        &quot;rating&quot;: &quot;4.7459&quot;
      }
    },
    ...
  ],
  ...
}
</code></pre>
<p>The validation of the contents of <code>custom_details</code> will look more like A.</p>
<pre><code class="language-json">{
  &quot;$schema&quot;: &quot;https://json-schema.org/draft/2020-12/schema&quot;,
  &quot;title&quot;: &quot;Suggest API Response v1&quot;,
  &quot;description&quot;: &quot;Response for /api/v1/suggest&quot;,
  &quot;type&quot;: &quot;object&quot;,
  &quot;properties&quot;: {
    &quot;provider&quot;: {
      &quot;description&quot;: &quot;id for the provider type&quot;,
      &quot;type&quot;: &quot;string&quot;
    }
  },
  &quot;required&quot;: [
    &quot;provider&quot;
  ],
  &quot;if&quot;: {
    &quot;properties&quot;: {
      &quot;provider&quot;: {
        &quot;const&quot;: &quot;addons&quot;
      }
    }
  },
  &quot;then&quot;: {
    &quot;properties&quot;: {
      &quot;custom_details&quot;: {
        &quot;description&quot;: &quot;Custom Details Specific for Addons&quot;,
        &quot;type&quot;: &quot;object&quot;,
        &quot;properties&quot;: {
          &quot;rating&quot;: {
            &quot;type&quot;: &quot;string&quot;
          }
        },
        &quot;required&quot;: [
          &quot;rating&quot;
        ]
      }
    },
    &quot;required&quot;: [&quot;custom_details&quot;]
  }
}
</code></pre>
<h4 id="pros-4"><a class="header" href="#pros-4">Pros</a></h4>
<ul>
<li>Can specify specific validation per provider.</li>
<li>Fields outside of <code>custom_details</code> can be fields that are more universal across suggestions.
These fields can potentially be correlated directly to the Fx Suggest Design Framework
(i.e. <code>context_label</code>, <code>url</code>, <code>title</code>, <code>description</code>, etc.).</li>
<li>Having a clear distinction for Fx Suggest Design Framework fields vs. bespoke fields makes this more
backwards compatible, as the fields in the Design Framework can render the <em>default</em> suggestion case
for clients who haven't upgraded their clients.</li>
<li>Less nesting in the response than B</li>
</ul>
<h4 id="cons-4"><a class="header" href="#cons-4">Cons</a></h4>
<ul>
<li>We'll likely need to migrate existing providers at some point. But in the meantime,
some fields will not follow convention to maintain backwards compatibility.</li>
<li>The relationship between <code>provider</code> and <code>custom_details</code> is more implicit, than explicit.</li>
<li>This has a lot of the same <em>cons</em> as Option A because validation is done similarly.</li>
</ul>
<h3 id="c-custom-details-field-for-a-type"><a class="header" href="#c-custom-details-field-for-a-type">C. Custom Details Field for a &quot;Type&quot;</a></h3>
<p>This is similar to option B, except that we want to introduce a new <code>type</code> field
to differentiate it from the provider.
The <code>custom_details</code> will be keyed by this type, rather than the <code>provider</code> name.
These <code>types</code> are kind of analogous to a <em>rendering component</em>,
as they will likely be used to specify a specific rendering path in the client.</p>
<p>Example:</p>
<pre><code class="language-json">{
  &quot;suggestions&quot;: [
    {
      ...
      &quot;provider&quot;: &quot;addons&quot;,
      &quot;type&quot;: &quot;addons_type&quot;,
      &quot;custom_details&quot;: {
        &quot;addons_type&quot;: {
          &quot;rating&quot;: &quot;4.7459&quot;
        }
      }
    },
    ...
  ],
  ...
}
</code></pre>
<h4 id="pros-5"><a class="header" href="#pros-5">Pros</a></h4>
<ul>
<li>All the pros for B applies here</li>
<li>Can decouple the <code>custom_details</code> from <code>provider</code>. This will be helpful for potentially
sharing the <code>type</code> with other suggestions produced by different providers. For instance,
we may want this to specify different <em>rendering</em> paths in the client
(i.e. a &quot;top picks&quot; type to be shared between <code>addons</code> and <code>top_picks</code> providers,
as there's many shared fields because they're rendered similarly).</li>
</ul>
<h4 id="cons-5"><a class="header" href="#cons-5">Cons</a></h4>
<ul>
<li>All the cons for B applies here</li>
<li>Potentially over-engineering for <code>type</code>, as it's use is currently hypothetical.</li>
</ul>
<h3 id="d-component-driven-custom_details"><a class="header" href="#d-component-driven-custom_details">D. Component Driven <code>custom_details</code></a></h3>
<p>This solution will model distinct UI components in the <code>custom_details</code> section.
For example, if the <code>addons</code> provider have specific UI components to render a <code>ratings</code> component and
a <code>highlight_context_label</code>, then we can specify these directly in the <code>custom_details</code> section.
This will assume that the client side have these specific rendering types.</p>
<p>Example:</p>
<pre><code class="language-json">{
  &quot;suggestions&quot;: [
    {
      ...
      &quot;provider&quot;: &quot;addons&quot;,
      &quot;custom_details&quot;: {
        &quot;ratings&quot;: {
          &quot;value&quot;: &quot;4.7459&quot;,
          &quot;unit&quot;: &quot;stars&quot;
        },
        &quot;highlight_context_label&quot;: {
          &quot;text&quot;: &quot;Special Limited Time Offer!&quot;
        }
      }
    },
    ...
  ],
  ...
}
</code></pre>
<h4 id="pros-6"><a class="header" href="#pros-6">Pros</a></h4>
<ul>
<li>Can share custom components with schema validation.</li>
<li>Backwards compatible with clients who don't have the necessary components to render.
It will just use the default renderer via the Fx Suggest Design Framework</li>
</ul>
<h4 id="cons-6"><a class="header" href="#cons-6">Cons</a></h4>
<ul>
<li>We currently don't have a sophisticated Component Design Framework, so this is probably overengineering.</li>
<li>This tightly couples the API to the design framework of Desktop Firefox, which makes the fields potentially
less relevant to other clients.</li>
</ul>
<h2 id="links-1"><a class="header" href="#links-1">Links</a></h2>
<ul>
<li><a href="https://json-schema.org/">JSON Schema Specification</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="streamline-test-coverage-of-third-party-integrations"><a class="header" href="#streamline-test-coverage-of-third-party-integrations">Streamline Test Coverage of Third-Party Integrations</a></h1>
<ul>
<li><strong>Status:</strong> Accepted</li>
<li><strong>Deciders:</strong> Nan Jiang &amp; Katrina Anderson</li>
<li><strong>Date:</strong> 2024-01-24</li>
</ul>
<h2 id="context-and-problem-statement-2"><a class="header" href="#context-and-problem-statement-2">Context and Problem Statement</a></h2>
<p>In 2024, it is anticipated that Merino will expand to be consumed by a greater set of Firefox
surfaces and to include more content providers. This will challenge the current feature test
strategy, which has shown weakness in detecting incompatibilities with third-party integrations.
Examples:</p>
<ol>
<li><a href="https://docs.google.com/document/d/1hQKTro1ulxrurPBybUVHguVGgt7xCPED-ZJAOtlDqsU/edit#">Weather Incident with Redis Integration</a></li>
<li><a href="https://github.com/mozilla-services/merino-py/pull/467">Navigation Suggestions Error with GCP Integration</a></li>
</ol>
<p>The current test approach uses a combination of unit, integration, and contract feature tests,
where third-party integrations such as cloud services, data storage services, and external API
integrations are <a href="https://martinfowler.com/articles/mocksArentStubs.html#TheDifferenceBetweenMocksAndStubs">test doubled</a> in the unit and integration tests and emulated with Docker
containers in contract tests. While test doubles might be easier to work with, they lack the
accuracy of working with real dependencies in terms of matching the production environment and
covering all the integration surfaces and concerns in tests.</p>
<p>Despite the potential to test with third-party integrations in contract tests, developers have
refrained due to their lack of familiarity with Docker and CI tooling, as well as their belief
in a poor return on investment for the time and effort required to create and maintain contract
tests for experimental features.</p>
<p>Given the Merino service context, which has a rapid development pace and a high risk tolerance,
is there a way to streamline the test strategy while ensuring robustness against third-party
integrations?</p>
<h2 id="decision-drivers-2"><a class="header" href="#decision-drivers-2">Decision Drivers</a></h2>
<p><strong>1. Usability &amp; Skill Transferability</strong></p>
<p>Ease-of-use is the key criterion when we assess a tool for testing. The test strategy should
prefer tools that require less effort and time to acquire proficiency. It should be easy to
learn and work with. Ideally, any skills or knowledge acquired should be applicable across
current contexts or for future scenarios.</p>
<p><strong>2. Maturity &amp; Expandability</strong></p>
<p>The test strategy and tooling should be able to handle known third-party Merino dependencies
in tests with a reasonable belief that it will cover future growth. Known third-party
dependencies include: REST APIs, Remote Settings, GCP Cloud Storage, Redis, and Elasticsearch.
Future dependencies include: relational DBMS such as PostgreSQL and other GCP cloud services
such as Pub/Sub.</p>
<p><strong>3. Cost Efficiency</strong></p>
<p>The worker hours and tooling expenditures associated with the implementation and execution of
the test strategy should ensure the profitability of Merino.</p>
<h2 id="considered-options-2"><a class="header" href="#considered-options-2">Considered Options</a></h2>
<ul>
<li>A. Yes. Expand the Scope of Integration Tests Using Dependency Docker Containers (Testcontainers)</li>
<li>B. Yes. Reduce the Dependency Overhead in Tests Using Development and Stage Environments</li>
<li>C. No. Fulfill the Current Test Strategy with Contract Test Coverage (Status quo)</li>
</ul>
<h2 id="decision-outcome-2"><a class="header" href="#decision-outcome-2">Decision Outcome</a></h2>
<p><strong>Chosen option: A</strong></p>
<p>Overall, we believe that increasing the scope of integration tests to verify third-party
integrations with <a href="https://testcontainers.com/">Testcontainers</a> will be the most effective and sustainable way forward.
Testcontainers' &quot;Test dependencies as code&quot; approach best fulfills the Usability &amp; Skill
Transferability and Maturity &amp; Expandability decision drivers and long-term would prove to be
the most Cost Efficient option.</p>
<p>We expect there to be initial labour costs to integrating Testcontainers, but anticipate that
moving more verification responsibility to the integration test layer will be more accessible
for developers and will reduce bugs found between Merino and third-party integrations.</p>
<p>Testcontainers is a widely adopted container-based test platform that supports a wide range of
programming languages including Python and Rust, which are popular at Mozilla and there is
indication that Testcontainers would have applicability across services in PXI. Given the success
of Rapid Release and other experiments in Merino, it's a good candidate to use in Merino first as
a pilot test. Should we find any issues or unsoundness about it, we can always revert the decision
in the future.</p>
<h2 id="pros-and-cons-of-the-options-2"><a class="header" href="#pros-and-cons-of-the-options-2">Pros and Cons of the Options</a></h2>
<h3 id="a-yes-expand-the-scope-of-integration-tests-using-dependency-docker-containers-testcontainers"><a class="header" href="#a-yes-expand-the-scope-of-integration-tests-using-dependency-docker-containers-testcontainers">A. Yes. Expand the Scope of Integration Tests Using Dependency Docker Containers (Testcontainers)</a></h3>
<p>A preference for the unit and integration feature test layers in Merino has emerged over time.
These test layers are white-box, which means developers can more easily set up program environments
to test either happy paths or edge cases. In addition, tooling for debugging and measuring code
coverage is readily available in these layers.<a href="https://testcontainers.com/">Testcontainers</a> can be used to increase the scope
of integration tests, covering the backend layer logic and network communication with third-party
integrations, the current test strategy's point of weakness.</p>
<h4 id="pros-7"><a class="header" href="#pros-7">Pros</a></h4>
<ul>
<li>Testcontainers works with any Docker image and has numerous pre-built modules. Almost all the
existing dependencies (or their close emulators) of Merino can be run as Docker containers. As a
result, we can use real dependencies in Merino's tests as opposed to test doubles</li>
<li>Testcontainers allows developers to programmatically manage the lifecycle of containers in the
test code. This simplifies its usage for developers, who will not need to run any Docker commands
separately for testing</li>
<li>Testcontainers, which has <a href="https://www.docker.com/blog/docker-whale-comes-atomicjar-maker-of-testcontainers/">recently been acquired by Docker</a>, is fairly mature and supports
many popular programming languages. There are also a large number of community maintained clients
available for popular services such as PostgreSQL, Redis, Elasticsearch, etc.</li>
<li>Testcontainers is lightweight and sandboxed, meaning service resources aren't shared and are
cleaned up automatically, promoting test isolation and parallelization</li>
<li>Docker-compose is also supported by Testcontainers, facilitating use of multiple dependency
containers for more complex test cases</li>
<li>Testcontainers supports Python, Rust and Javascript languages and works well with their respective
test frameworks <a href="https://docs.pytest.org/en/7.4.x/">PyTest</a>, <a href="https://doc.rust-lang.org/cargo/guide/tests.html">Cargo-Test</a> and <a href="https://jestjs.io/">Jest</a></li>
</ul>
<h4 id="cons-7"><a class="header" href="#cons-7">Cons</a></h4>
<ul>
<li>A Docker runtime is required to run all the tests that depend on Testcontainers. Docker is
already setup in CI, but developers may need to install a Docker runtime locally</li>
<li>Integration tests cannot be run completely offline as Docker images need to be downloaded first</li>
<li>Developers will need to understand more about how to configure and work with dependency
containers. The development community has many popular services out of the box, but developers
would still need to know and do more than what's required when using test doubles</li>
<li>It could be challenging to provision test fixtures for the underlying containers. Feeding the
fixture data into the containers could be complex</li>
<li>Developers need to ensure version consistency across the development, testing, and production
environments in the integration test layer</li>
<li>For third-party API integrations, if the provider doesn't provide a Docker image for their API,
Testcontainers alone will not help us much. It's possible to use fake API container generators,
such as <a href="https://wiremock.org/">Wiremock</a>, but it comes with its own complexities</li>
<li>Implementation of Testcontainers would require refactoring of integration tests, including the
removal of mocks and fixtures</li>
</ul>
<h3 id="b-yes-reduce-the-dependency-overhead-in-tests-using-development-and-stage-environments"><a class="header" href="#b-yes-reduce-the-dependency-overhead-in-tests-using-development-and-stage-environments">B. Yes. Reduce the Dependency Overhead in Tests Using Development and Stage Environments</a></h3>
<p>Using Merino's staging environment and third-party development resources in tests has been
considered. This would effectively cover the current test strategy's weakness with third-party
integrations without the cost and complexity involved with setting up test doubles or dependency
containers. However, this approach has a key challenge in how to share the stage environment
across all the test consumers (devs &amp; CI) as most of the services do not support multi-tenant
usage and would require a significant amount of effort to support resource isolation.</p>
<h4 id="pros-8"><a class="header" href="#pros-8">Pros</a></h4>
<ul>
<li>Best matches the production environment</li>
<li>Doesn't need extra effort to create test doubles or dependencies for testing</li>
</ul>
<h4 id="cons-8"><a class="header" href="#cons-8">Cons</a></h4>
<ul>
<li>Tests cannot be run offline since they would require a network connection to interact with
development and stage environments</li>
<li>This option breaks the <a href="https://github.com/mozilla-services/merino-py/blob/disco-2704/CONTRIBUTING.md#testing-guidelines--best-practices">Testing Guidelines &amp; Best Practices</a> for Merino, which require tests
to be isolated and repeatable. A dependency on shared network resources will almost certainly
lead to test flake, reducing the confidence in the test suite</li>
<li>Test execution speeds would be negatively impacted, due to the lack of sandboxing, which enables
parallel test runs</li>
</ul>
<h3 id="c-no-fulfill-the-current-test-strategy-with-contract-test-coverage-status-quo"><a class="header" href="#c-no-fulfill-the-current-test-strategy-with-contract-test-coverage-status-quo">C. No. Fulfill the Current Test Strategy with Contract Test Coverage (Status quo)</a></h3>
<p>The current test strategy, which relies on the contract tests to verify the interface between
Merino and third-party dependencies, has not been fully implemented as designed. The missing
coverage explains the current test strategy's weakness.
Examples:</p>
<ol>
<li><a href="https://mozilla-hub.atlassian.net/browse/DISCO-2032">DISCO-2032: Weather Contract Tests</a></li>
<li><a href="https://mozilla-hub.atlassian.net/browse/DISCO-2324">DISCO-2324: Add a merino-py contract test that interacts with a real Redis instance</a></li>
<li><a href="https://mozilla-hub.atlassian.net/browse/DISCO-2055">DISCO-2055: Dynamic Wikipedia Contract Tests</a></li>
</ol>
<h4 id="pros-9"><a class="header" href="#pros-9">Pros</a></h4>
<ul>
<li>The most cost-effective solution, at least in the short term, since the test framework and Docker
dependencies are set up and integrated into CI</li>
<li>The unit and integration feature test layers remain simple by using test doubles</li>
</ul>
<h4 id="cons-9"><a class="header" href="#cons-9">Cons</a></h4>
<ul>
<li>The black-box nature of contract tests makes it harder to set up the environmental conditions
required to enable testing edge cases</li>
<li>Adding dependency containers is complex, often requiring developers to have advanced knowledge
of Docker and CI vendors (e.g. CircleCI)</li>
<li>There is a high level of redundancy between unit, integration, and contract tests that negatively
impacts development pace</li>
</ul>
<h2 id="open-questions"><a class="header" href="#open-questions">Open Questions</a></h2>
<ul>
<li>How to test 3rd party API integrations? We have two options for consideration: Either use
generic API mocking frameworks or keep status quo and rely on other means (e.g. observerbility)
to capture API breakages. They both have pros and cons and warrant a separate ADR to discuss
in detail</li>
</ul>
<h2 id="links-2"><a class="header" href="#links-2">Links</a></h2>
<ul>
<li><a href="https://mozilla-hub.atlassian.net/browse/DISCO-2055">DISCO-2704 - Use Testcontainer for Merino</a></li>
</ul>
<!-- References -->

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="mermaid.min.js"></script>
        <script src="mermaid-init.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </body>
</html>
